{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Signal analysis\n",
    " \n",
    " Analyze the performance of beamforming with different filtering schemes, such as snr-based filtering, props filtering, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "\n",
    "import IPython\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"figure.max_open_warning\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_data import read_df\n",
    "from crazyflie_description_py.parameters import N_BUFFER, FS, FFTSIZE\n",
    "import itertools\n",
    "\n",
    "exp_name = '2020_11_03_sweep'; start_idx = 20\n",
    "\n",
    "all_frequencies = np.round(np.fft.rfftfreq(N_BUFFER, 1/FS), 0)\n",
    "#print(list(all_frequencies))\n",
    "\n",
    "df_results = pd.DataFrame(columns=[\n",
    "    'degree', \n",
    "    'props',\n",
    "    'snr',\n",
    "    'motors',\n",
    "    'source',\n",
    "    'times',\n",
    "    'spectrogram',\n",
    "    'frequency_matrix',\n",
    "    'strongest_freqs'\n",
    "])\n",
    "\n",
    "DEGREE_LIST = [90]\n",
    "PROPS_LIST = [False, True]\n",
    "SNR_LIST = [False, True]\n",
    "MOTORS_LIST = [False, True]\n",
    "SOURCE_LIST = ['sweep']\n",
    "\n",
    "for params_values in itertools.product(DEGREE_LIST, PROPS_LIST, SNR_LIST, MOTORS_LIST, SOURCE_LIST):\n",
    "    params_dict = dict(zip(['degree', 'props', 'snr', 'motors', 'source'], params_values))\n",
    "    params_dict['exp_name'] = exp_name\n",
    "\n",
    "    df, df_pos = read_df(**params_dict)\n",
    "    df = df.iloc[start_idx:]\n",
    "    \n",
    "    frequency_matrix = np.zeros((len(all_frequencies), len(df)))\n",
    "    i_col = 0\n",
    "    for j, row in df.iterrows():\n",
    "        # check if frequencies are sorted\n",
    "        #if not np.all(np.diff(row.frequencies) >= 0):\n",
    "            #print('not sorted:', params_dict)\n",
    "        for f in row.frequencies:\n",
    "            \n",
    "            # find the closest frequency bin to chosen frequency\n",
    "            idx = np.argmin(np.abs(f-all_frequencies))\n",
    "            err = abs(all_frequencies[idx] - f)\n",
    "            #if err >= 1e-1:\n",
    "                #print(f'did not find {f} in bins. error:', err)\n",
    "            frequency_matrix[idx, i_col] = 1.0 \n",
    "        sum_ = np.sum(frequency_matrix[:, i_col])\n",
    "        assert sum_ == FFTSIZE, sum_\n",
    "        i_col += 1\n",
    "        \n",
    "    spectrogram = np.zeros((FFTSIZE, len(df)))\n",
    "    strongest_freqs = np.zeros(len(df))\n",
    "    i_col = 0\n",
    "    for __, row in df.iterrows():\n",
    "        signals_f = row.signals_f\n",
    "        \n",
    "        spectrogram[:, i_col] = np.sum(np.abs(signals_f), axis=0)\n",
    "        \n",
    "        max_idx = np.argmax(spectrogram[:, i_col])\n",
    "        #if params_dict['snr']:\n",
    "        #    assert max_idx == 0, max_idx\n",
    "        strongest_freqs[i_col] = row.frequencies[max_idx]\n",
    "        i_col += 1\n",
    "    \n",
    "    params_dict['spectrogram'] = spectrogram\n",
    "    params_dict['strongest_freqs'] = strongest_freqs\n",
    "    params_dict['frequency_matrix'] = frequency_matrix\n",
    "    params_dict['times'] = (df.loc[:, 'audio_timestamp'].values - df.iloc[0].audio_timestamp) / 1e6\n",
    "    df_results.loc[len(df_results), :] = params_dict\n",
    "df_results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = len(SNR_LIST)*len(PROPS_LIST), len(MOTORS_LIST)\n",
    "fig, axs = plt.subplots(*shape, sharey=True, sharex=True)\n",
    "fig.set_size_inches(shape[0]*5, shape[1]*5)\n",
    "\n",
    "fig_spec, axs_spec = plt.subplots(*shape, sharey=True, sharex=True)\n",
    "fig_spec.set_size_inches(shape[0]*5, shape[1]*5)\n",
    "\n",
    "fig_scat, axs_scat = plt.subplots(*shape, sharex=True, sharey=True)\n",
    "fig_scat.set_size_inches(shape[0]*5, shape[1]*5)\n",
    "for j, motors in enumerate(MOTORS_LIST):\n",
    "    axs[0, j].set_title(f\"motors {motors}\")\n",
    "    axs_scat[0, j].set_title(f\"motors {motors}\")\n",
    "    for i, (snr, props) in enumerate(itertools.product(SNR_LIST, PROPS_LIST)):\n",
    "        row = df_results.loc[(df_results.motors==motors) & (df_results.snr==snr) & (df_results.props==props), :]\n",
    "        row = row.iloc[0]\n",
    "        spectrogram = row.spectrogram\n",
    "        spectrogram_wide = np.full((len(all_frequencies), spectrogram.shape[1]), np.nan)\n",
    "        mask = np.where(row.frequency_matrix > 0)\n",
    "        spectrogram_wide[mask[0], mask[1]] = spectrogram.flatten()\n",
    "        \n",
    "        times = row.times\n",
    "        \n",
    "        plot_mask = (all_frequencies < 7000) & (all_frequencies > 200)\n",
    "        \n",
    "        axs[i, j].pcolormesh(times, all_frequencies[plot_mask], np.log(spectrogram_wide[plot_mask]))\n",
    "        axs[i, 0].set_ylabel(f\"snr {snr} props {props}\")\n",
    "        \n",
    "        axs_spec[i, j].pcolormesh(times, range(FFTSIZE), np.log(spectrogram))\n",
    "        \n",
    "        axs_scat[i, j].scatter(times, row.strongest_freqs)\n",
    "        \n",
    "        axs_spec[i, j].set_ylabel(f\"snr {snr} props {props}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_stack.beam_former import BeamFormer, combine_rows, normalize_rows\n",
    "import progressbar\n",
    "\n",
    "DEGREE_LIST = [90]\n",
    "PROPS_LIST = [False, True]\n",
    "SNR_LIST = [False, True]\n",
    "MOTORS_LIST = [False, True]\n",
    "SOURCE_LIST = ['sweep']\n",
    "\n",
    "METHOD_LIST = ['mvdr', 'das']\n",
    "combination_method = 'sum'\n",
    "\n",
    "#INVERSE = 'pinv'\n",
    "#fname = f'results/SignalAnalysis_{exp_name}_pinv.pkl'\n",
    "\n",
    "INVERSE = 'low-rank'\n",
    "fname = f'results/SignalAnalysis_{exp_name}_low-rank.pkl'\n",
    "\n",
    "try:\n",
    "    df_spectra = pd.read_pickle(fname)\n",
    "    print('read', fname)\n",
    "except:\n",
    "    df_spectra = pd.DataFrame(columns=[\n",
    "        'degree', \n",
    "        'props',\n",
    "        'snr',\n",
    "        'motors',\n",
    "        'source',\n",
    "        'method',\n",
    "        'times',\n",
    "        'raw_heatmap',\n",
    "    ])\n",
    "\n",
    "    for params_values in itertools.product(DEGREE_LIST, PROPS_LIST, SNR_LIST, MOTORS_LIST, SOURCE_LIST):\n",
    "        params_dict = dict(zip(['degree', 'props', 'snr', 'motors', 'source'], params_values))\n",
    "        params_dict['exp_name'] = exp_name\n",
    "\n",
    "        df, df_pos = read_df(**params_dict)\n",
    "        df = df.iloc[start_idx:]\n",
    "        n_columns = len(df)\n",
    "        times = (df.loc[:, 'audio_timestamp'].values - df.iloc[0].audio_timestamp) / 1e6\n",
    "        mic_positions = df.iloc[0].mic_positions\n",
    "\n",
    "        for method, in itertools.product(METHOD_LIST):\n",
    "            print(method)\n",
    "            params_dict['method'] = method\n",
    "\n",
    "            beam_former = BeamFormer(mic_positions=mic_positions)\n",
    "            angles = beam_former.theta_scan\n",
    "            raw_heatmap = np.zeros((len(angles), n_columns))\n",
    "\n",
    "            i_col = 0\n",
    "            with progressbar.ProgressBar(max_value=n_columns, redirect_stdout=True) as p:\n",
    "                for __, row in df.iterrows():\n",
    "\n",
    "                    # choose strongest frequency\n",
    "                    spectrogram = np.sum(np.abs(row.signals_f), axis=0)\n",
    "                    selected_idx = [np.argmax(spectrogram)]\n",
    "\n",
    "                    signals_f = row.signals_f[:, selected_idx] # n_mics x n_freqs\n",
    "                    freqs = row.frequencies[selected_idx]\n",
    "\n",
    "                    R = beam_former.get_correlation(signals_f.T)\n",
    "                    if method == 'mvdr':\n",
    "                        raw_spectrum = beam_former.get_mvdr_spectrum(R, freqs, inverse=INVERSE)\n",
    "                    elif method == 'das':\n",
    "                        raw_spectrum = beam_former.get_das_spectrum(R, freqs)\n",
    "                    else:\n",
    "                        raise ValueError(method)\n",
    "\n",
    "                    raw_spectrum = combine_rows(raw_spectrum, combination_method, keepdims=True)\n",
    "                    raw_spectrum = normalize_rows(raw_spectrum, method=\"zero_to_one\")\n",
    "                    raw_heatmap[:, i_col] = raw_spectrum.flatten()\n",
    "\n",
    "                    i_col += 1\n",
    "                    p.update(i_col)\n",
    "                    if i_col >= n_columns:\n",
    "                        break\n",
    "\n",
    "                params_dict['raw_heatmap'] = raw_heatmap\n",
    "                params_dict['times'] = times \n",
    "                df_spectra.loc[len(df_spectra), :] = params_dict\n",
    "    df_spectra.to_pickle(fname)\n",
    "    print('saved as', fname)\n",
    "df_spectra.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#angles = BeamFormer.theta_scan\n",
    "angles = np.linspace(0, 360, df_spectra.iloc[0].raw_heatmap.shape[0])\n",
    "\n",
    "# TODO(FD): read these from parameters file\n",
    "min_freq = 200\n",
    "max_freq = 7000\n",
    "\n",
    "for method in METHOD_LIST:\n",
    "\n",
    "    fig_spec, axs_spec = plt.subplots(*shape, sharey=True, sharex=True)\n",
    "    fig_spec.set_size_inches(shape[0]*5, shape[1]*5)\n",
    "\n",
    "    for j, motors in enumerate(MOTORS_LIST):\n",
    "        axs[0, j].set_title(f\"motors {motors}\")\n",
    "        axs_scat[0, j].set_title(f\"motors {motors}\")\n",
    "        for i, (snr, props) in enumerate(itertools.product(SNR_LIST, PROPS_LIST)):\n",
    "            row = df_spectra.loc[\n",
    "                (df_spectra.motors==motors) & \n",
    "                (df_spectra.snr==snr) & \n",
    "                (df_spectra.props==props) & \n",
    "                (df_spectra.method==method), :]\n",
    "            row = row.iloc[0]\n",
    "            heatmap = row.raw_heatmap\n",
    "\n",
    "            times = row.times\n",
    "            plot_mask = (all_frequencies < max_freq) & (all_frequencies > min_freq)\n",
    "\n",
    "            axs_spec[i, j].pcolormesh(times, angles, heatmap)\n",
    "            axs_spec[i, 0].set_ylabel(f\"snr {snr} props {props}\")\n",
    "            axs_spec[i, 1].set_ylabel(f\"snr {snr} props {props}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algos_basics import low_rank_inverse\n",
    "\n",
    "def low_rank_tensor_inverse(low_rank_tensor, rank=1):\n",
    "    # low_rank_tensor is of shape n x m x m, and we take the inverse\n",
    "    # of each m x m slice. \n",
    "    u, s, vt = np.linalg.svd(low_rank_tensor, full_matrices=True)\n",
    "    \n",
    "    # TODO(FD) could be done more efficiently with broadcasting? \n",
    "    s_mat = np.concatenate([[np.zeros((s.shape[1], s.shape[1]))]]*s.shape[0])\n",
    "    s_mat[:, range(rank), range(rank)] = 1 / s[..., :rank]\n",
    "    a = np.transpose(vt, (0, 2, 1))\n",
    "    b = np.transpose(u, (0, 2, 1))\n",
    "    \n",
    "    # TODO(FD understand why below we need to take element 0)\n",
    "    inverse = a.dot(s_mat).dot(b)[:, :, 0, 0, :]\n",
    "    #inverse = np.matmul(a, s_mat, b)\n",
    "    return inverse\n",
    "\n",
    "n_mics = 4\n",
    "lamda = 1e-3\n",
    "#signals_f = np.arange(1, n_mics+1).reshape((n_mics, 1))\n",
    "signals_f = np.random.rand(1, n_mics).reshape((n_mics, 1))\n",
    "signals_f_ = np.random.rand(1, n_mics).reshape((n_mics, 1))\n",
    "rank_1 = signals_f.dot(signals_f.T) \n",
    "rank_1_ = signals_f_.dot(signals_f_.T) \n",
    "rank_1_tensor = np.concatenate([rank_1[None, :, :], rank_1_[None, :, :]], axis=0)\n",
    "\n",
    "own_tensor = low_rank_tensor_inverse(rank_1_tensor)\n",
    "own = low_rank_inverse(rank_1 + lamda*np.eye(n_mics))\n",
    "own_ = low_rank_inverse(rank_1_)\n",
    "\n",
    "print('tensor', own_tensor)\n",
    "print('own', own.dot(rank_1))\n",
    "print('own_', own_.dot(rank_1_))\n",
    "\n",
    "pinv = np.linalg.pinv(rank_1)\n",
    "inv = np.linalg.inv(rank_1 + lamda*np.eye(n_mics))\n",
    "print(pinv.dot(rank_1))\n",
    "print(inv.dot(rank_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
