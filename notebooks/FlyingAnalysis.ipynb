{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "\n",
    "import IPython\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"figure.max_open_warning\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wall_analysis import parse_experiments\n",
    "exp_name = '2020_12_18_flying'; \n",
    "fname = f'results/{exp_name}_real.pkl'\n",
    "\n",
    "try:\n",
    "    df_total = pd.read_pickle(fname)\n",
    "    print('read', fname)\n",
    "except:\n",
    "    answer = input('Run wall_analysis.py to parse experiments? (y/[n])') or 'n'\n",
    "    if answer == 'y':\n",
    "        df_total = parse_experiments(exp_name)\n",
    "        pd.to_pickle(df_total, fname)\n",
    "        print('saved', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute distance estimates\n",
    "\n",
    "TODO: this part is hacky and will be improved by getting imu estimates rather than flow dx/dy estimates, which turn out to be very unreliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MIN_S = 5\n",
    "MAX_S = 25\n",
    "VELOCITY = 0.05\n",
    "D_START = 0.6 # m\n",
    "\n",
    "df_total = df_total.assign(d_estimate=None) # initialize df_estimate\n",
    "for i, row in df_total.iterrows():\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(row.positions[:, 0], label='x', color='C0')\n",
    "    ax.plot(row.positions[:, 1], label='y', color='C1')\n",
    "    ax.plot(row.positions[:, 2], label='z', color='C2')\n",
    "    #ax.plot(row.dx)\n",
    "    #ax.plot(row.dy)\n",
    "    ax.set_ylim(-50, 50)\n",
    "    #ax.set_xlim(0, 1000)\n",
    "    ax.set_xlabel('position idx [-]')\n",
    "    ax.set_ylabel('x, y [mm]')\n",
    "    ax.legend(loc='lower left')\n",
    "    ax.set_title(\"lateral movement, \" + row.source + row.appendix)\n",
    "    \n",
    "    plt.figure()\n",
    "    #plt.plot(row.yaw_deg)\n",
    "    plt.plot(row.seconds, row.z, color='C2')\n",
    "    plt.xlabel('time [s]')\n",
    "    plt.ylabel('z [mm]')\n",
    "    #plt.ylim(-90, 90)\n",
    "    plt.ylim(0, 600)\n",
    "    #plt.xlim(MIN_S, MAX_S)\n",
    "    \n",
    "    row.z[np.isnan(row.z)] = 0\n",
    "    start_idx = np.where(row.seconds > MIN_S)[0][0]\n",
    "    end_idx = np.where(row.seconds < MAX_S)[0][-1]\n",
    "    \n",
    "    assert end_idx > start_idx, f\"{start_idx}<={end_idx}\"\n",
    "    valid_z = row.z[start_idx:end_idx]\n",
    "    max_idx = start_idx + np.argmax(valid_z)\n",
    "    min_idx = start_idx + np.where(valid_z > 300)[0][-1]\n",
    "    duration = row.seconds[min_idx] - row.seconds[max_idx]\n",
    "    plt.axvline(row.seconds[start_idx], color='r')\n",
    "    plt.axvline(row.seconds[max_idx], color='k')\n",
    "    plt.axvline(row.seconds[min_idx], color='k')\n",
    "    plt.axvline(row.seconds[end_idx], color='b')\n",
    "    plt.xlim(0, 35)\n",
    "    plt.title(f\"duration: {duration:.1f}s\")\n",
    "    \n",
    "    d = np.full(len(row.seconds), np.nan)\n",
    "    times = row.seconds[max_idx:min_idx] - row.seconds[max_idx]\n",
    "    d[max_idx:min_idx] = D_START - times * VELOCITY\n",
    "    plt.figure()\n",
    "    plt.scatter(row.seconds, d)\n",
    "    plt.ylim(0, 0.6)\n",
    "    \n",
    "    df_total.loc[i, 'd_estimate'] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wall_analysis import filter_by_dicts\n",
    "filter_dict = {\n",
    "    'source': 'mono3875',\n",
    "    'appendix': '_new'\n",
    "}\n",
    "rows =filter_by_dicts(df_total, [filter_dict])\n",
    "assert len(rows) == 1\n",
    "row = rows.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
