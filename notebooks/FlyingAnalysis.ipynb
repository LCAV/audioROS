{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "\n",
    "import IPython\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"figure.max_open_warning\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wall_analysis import parse_experiments\n",
    "import seaborn as sns\n",
    "from plotting_tools import save_fig\n",
    "\n",
    "def plot_plositions(row, min_time=None, max_time=None, max_dist=None):\n",
    "    positions_cm = row.positions[:, :3] * 100\n",
    "    fig, axs = plt.subplots(1, 3) \n",
    "    fig.set_size_inches(10, 3.3)\n",
    "    fig.suptitle(row.appendix, y=1.0)\n",
    "    \n",
    "    mask_time = np.ones_like(row.seconds, dtype=np.bool)\n",
    "    if min_time is not None:\n",
    "        mask_time = (row.seconds > min_time) \n",
    "    if max_time is not None:\n",
    "        mask_time = mask_time & (row.seconds < max_time)\n",
    "        \n",
    "    time = row.seconds[mask_time]\n",
    "    \n",
    "    #axs[0].plot(x=positions_cm[:, 0], y=positions_cm[:, 1], color=colors())\n",
    "    sns.scatterplot(x=positions_cm[mask_time, 0], y=positions_cm[mask_time, 1], \n",
    "                    hue=time, ax=axs[0], linewidth=0, \n",
    "                    #size=positions_cm[:, 2],\n",
    "                    palette='inferno')\n",
    "    axs[0].set_xlabel('x [cm]')\n",
    "    axs[0].set_ylabel('y [cm]')\n",
    "    axs[0].axis('equal')\n",
    "    axs[0].legend(loc='lower right', title='time [s]')\n",
    "\n",
    "    axs[1].plot(time, positions_cm[mask_time, 0], label='x')\n",
    "    axs[1].plot(time, positions_cm[mask_time, 1], label='y')\n",
    "    axs[1].plot(time, positions_cm[mask_time, 2], label='z')\n",
    "    axs[1].set_xlabel('time [s]')\n",
    "    axs[1].set_ylabel('movement [cm]')\n",
    "    if max_dist is not None:\n",
    "        axs[1].set_ylim(-max_dist, max_dist)\n",
    "    axs[1].legend(loc='lower right')\n",
    "\n",
    "    axs[2].plot(time, row.positions[mask_time, 3], label='yaw')\n",
    "    axs[2].set_ylabel('yaw [deg]')\n",
    "    axs[2].set_xlabel('time [s]')\n",
    "    axs[2].set_ylim(-20, 20)\n",
    "    axs[2].legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "    return fig, axs\n",
    "\n",
    "def plot_audio(row, mic_idx=0):\n",
    "    all_frequencies = np.unique(row.frequencies_matrix)\n",
    "    spec = row.spectrogram[:, mic_idx, :]\n",
    "    spec[spec == 0] = np.nan\n",
    "    total = np.nanmean(np.abs(spec), axis=1)\n",
    "    \n",
    "    label = str(f\"{row.appendix}\").replace('_', '')\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(10, 5)\n",
    "    ax.set_title(f'spectrogram of mic{mic_idx}, appendix {row.appendix}')\n",
    "    \n",
    "    # mark too long measurements gray\n",
    "    max_diff = 1\n",
    "    diff = row.seconds[1:] - row.seconds[:-1]\n",
    "    indices = np.where(diff>max_diff)[0]\n",
    "    endings = row.seconds[:-1][indices]\n",
    "    diff_average = np.mean(diff[diff<max_diff])\n",
    "    seconds = row.seconds\n",
    "    for counter, i in enumerate(indices):\n",
    "        new_time = seconds[i+counter]+diff_average\n",
    "        seconds = np.insert(seconds, i+counter+1, new_time)\n",
    "        spec = np.insert(spec, i+counter+1, np.nan, axis=1)\n",
    "    \n",
    "    pcolorfast_custom(ax, seconds, all_frequencies, np.abs(spec))\n",
    "    \n",
    "    xticks = np.arange(0, row.seconds.max(), step=5)\n",
    "    ax.set_xticks(xticks); ax.set_xticklabels(xticks)\n",
    "    yticks = np.arange((np.round(row.frequencies_matrix.min()//1000)+1)*1000, \n",
    "                       row.frequencies_matrix.max(), step=1000)\n",
    "    ax.set_yticks(yticks); ax.set_yticklabels(yticks)\n",
    "    ax.set_ylabel('frequency [Hz]')\n",
    "    ax.set_xlabel('seconds [s]')\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Frequency slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp_name = '2020_12_18_stepper'; appendix = \"\"; distance = 51\n",
    "#exp_name = '2020_12_18_flying'; appendix=\"_new\"; distance = 0\n",
    "#exp_name = '2021_03_01_flying';\n",
    "#exp_name = '2021_04_30_hover';\n",
    "exp_name = '2021_05_04_flying';\n",
    "fname = f'../experiments/{exp_name}/all_data.pkl'\n",
    "\n",
    "try:\n",
    "    df_total = pd.read_pickle(fname)\n",
    "    print('read', fname)\n",
    "except:\n",
    "    answer = input('Run wall_analysis.py to parse experiments? (y/[n])') or 'n'\n",
    "    if answer == 'y':\n",
    "        df_total = parse_experiments(exp_name)\n",
    "        pd.to_pickle(df_total, fname)\n",
    "        print('saved', fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 positions analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geometry import Context\n",
    "context = Context.get_crazyflie_setup(dim=2)\n",
    "context.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_time = None\n",
    "max_time = None\n",
    "max_dist = None\n",
    "for i, row in df_total.iterrows():\n",
    "    fig, axs = plot_plositions(row, min_time, max_time, max_dist)\n",
    "    save_fig(fig, f'plots/{exp_name}{row.appendix}_movement.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 audio analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from frequency_analysis import add_spectrogram\n",
    "from plotting_tools import pcolorfast_custom\n",
    "\n",
    "df_total = df_total.assign(spectrogram=None)\n",
    "df_total = df_total.apply(add_spectrogram, axis=1)\n",
    "\n",
    "mic_idx = 0\n",
    "\n",
    "#maxi = np.nanmax(np.concatenate([*dfs.spectrogram], axis=1))\n",
    "for i_col, row in df_total.iterrows():\n",
    "    fig, ax = plot_audio(row, mic_idx=mic_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 algorithm performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the experiment to analyze\n",
    "row = df_total.iloc[0] # works well\n",
    "#row = df_total.iloc[1] # works ok\n",
    "#row = df_total.iloc[2] # doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibration import get_calibration_function_median, get_calibration_function_dict\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 5)\n",
    "if \"newbuzzer\" in row.appendix:\n",
    "    calib_function, calib_freq = get_calibration_function_median(\n",
    "        exp_name=\"2021_02_25_wall\", mic_type=\"audio_deck\", ax=ax\n",
    "    )\n",
    "else:\n",
    "    calib_function, calib_freq = get_calibration_function_median(\n",
    "        \"2021_04_30_stepper\", \"audio_deck\", ax=ax, #fit_one_gain=True \n",
    "    )\n",
    "#else:\n",
    "#    calib_function, calib_freq = get_calibration_function_median(\n",
    "#        exp_name=\"2021_02_23_wall\", mic_type=\"audio_deck\", ax=ax\n",
    "#    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_parameters import kwargs_datasets\n",
    "from simulation import get_df_theory\n",
    "from crazyflie_description_py.experiments import WALL_ANGLE_DEG\n",
    "\n",
    "azimuth_deg = WALL_ANGLE_DEG\n",
    "\n",
    "distance_range = [0, 70]\n",
    "kwargs = kwargs_datasets[exp_name][\"audio_deck\"]\n",
    "\n",
    "distances_grid = np.linspace(distance_range[0]+7, distance_range[1],100)\n",
    "freqs_theo = np.linspace(kwargs[\"min_freq\"], kwargs[\"max_freq\"], 200)\n",
    "\n",
    "df_matrix_theo = get_df_theory(freqs_theo, distances_grid, azimuth_deg=azimuth_deg, \n",
    "                               chosen_mics=[mic_idx])\n",
    "\n",
    "fig, ax_df = plt.subplots()\n",
    "xticks = [7, 10, 20, 30, 40, 50, 60, 70]\n",
    "yticks = np.arange(kwargs[\"min_freq\"], kwargs[\"max_freq\"]+1, step=1000)\n",
    "pcolorfast_custom(ax_df, distances_grid, freqs_theo, np.log10(df_matrix_theo[0]), cmap='Greys')\n",
    "ax_df.set_xticks(xticks); ax_df.set_xticklabels(xticks)\n",
    "ax_df.set_yticks(yticks); ax_df.set_yticklabels(yticks)\n",
    "ax_df.set_xlabel('distance [cm]')\n",
    "ax_df.set_ylabel('frequency [Hz]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# spec_masked, freqs_masked = data_collector.fill_from_row()\n",
    "from data_collector import DataCollector\n",
    "from estimators import DistanceEstimator\n",
    "from inference import get_probability_bayes\n",
    "from simulation import get_freq_slice_theory\n",
    "\n",
    "linestyles = {\"measured\": \"-\", \"theo\": \":\", \"theo_corr\": \"-.\"}\n",
    "EPS = 1e-10\n",
    "\n",
    "starting_distance = 60  # [50, 30, 10]\n",
    "nominal_distances = [60 - i * 20 for i in range(3)]\n",
    "slice_idx = 0\n",
    "\n",
    "data_collector = DataCollector(exp_name=exp_name)\n",
    "\n",
    "fig, ax_distance = plt.subplots()\n",
    "fig.set_size_inches(10, 5)\n",
    "ax_distance.set_xlabel(\"time idx\")\n",
    "ax_distance.set_ylabel(\"distance [cm]\")\n",
    "ax_distance.axhline(starting_distance, label=\"starting distance\", ls=\":\")\n",
    "ax_distance.set_title(f\"experiment {row.appendix}\")\n",
    "\n",
    "freqs_calib = np.linspace(\n",
    "    np.min(row.frequencies_matrix), np.max(row.frequencies_matrix), 50\n",
    ")\n",
    "f_calib_all = calib_function(freqs_calib)\n",
    "\n",
    "fig, ax_df = plt.subplots()\n",
    "pcolorfast_custom(ax_df, distances_grid, freqs_theo, np.log10(df_matrix_theo[0]), cmap='Greys', n_xticks=10)\n",
    "ax_df.set_xticks(xticks); ax_df.set_xticklabels(xticks)\n",
    "ax_df.set_yticks(yticks); ax_df.set_yticklabels(yticks)\n",
    "ax_df.set_xlabel('distance [cm]')\n",
    "ax_df.set_ylabel('frequency [Hz]')\n",
    "\n",
    "for i in range(row.stft.shape[0]):\n",
    "    signals_f = row.stft[i]\n",
    "    frequencies = row.frequencies_matrix[i]\n",
    "\n",
    "    if i == row.stft.shape[0] - 1:\n",
    "        sweep_complete = True\n",
    "    else:\n",
    "        sweep_complete = data_collector.next_fslice_ready(signals_f, frequencies)\n",
    "\n",
    "    if sweep_complete:\n",
    "        f_slice, freqs, stds, distances = data_collector.get_current_frequency_slice(\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        fig, ax_total = plt.subplots()\n",
    "        fig.set_size_inches(10, 5)\n",
    "        ax_total.set_xlabel(\"distance [cm]\")\n",
    "        ax_total.set_ylabel(\"probability\")\n",
    "        ax_total.set_title(f\"experiment {row.appendix}\")\n",
    "\n",
    "        fig, axs = plt.subplots(3, row.stft.shape[1])  # , sharey='row')\n",
    "        fig.set_size_inches(15, 10)\n",
    "        fig.suptitle(f\"up to {data_collector.latest_fslice_time:.1f}s\", y=0.9)\n",
    "        # fig.set_suptitle(f\"experiment {row.appendix}\")\n",
    "\n",
    "        # extract valid indices\n",
    "        valid_idx = (\n",
    "            (freqs >= min(calib_function.x))\n",
    "            & (freqs <= max(calib_function.x))\n",
    "            & ((3800 <= freqs) | (freqs <= 3700))\n",
    "        )\n",
    "        freqs = freqs[valid_idx]\n",
    "        f_calib = calib_function(freqs)\n",
    "        f_slice = f_slice[:, valid_idx]\n",
    "        distances = distances[valid_idx]\n",
    "\n",
    "        distance_corr = starting_distance - distances\n",
    "        ax_df.scatter(distance_corr, freqs, color=f\"C{slice_idx}\")\n",
    "\n",
    "        f_theo = get_freq_slice_theory(\n",
    "            freqs, distance_cm=nominal_distances[slice_idx], azimuth_deg=azimuth_deg\n",
    "        ).T  # n_mics x n_freqs\n",
    "        f_theo_corr = get_freq_slice_theory(\n",
    "            freqs, distance_cm=distance_corr, azimuth_deg=azimuth_deg\n",
    "        ).T\n",
    "\n",
    "        print(\"treating new frequency slice\")\n",
    "\n",
    "        distance_estimators = {\n",
    "            \"measured\": DistanceEstimator(),\n",
    "            \"theo\": DistanceEstimator(),\n",
    "            \"theo_corr\": DistanceEstimator(),\n",
    "        }\n",
    "\n",
    "        for i_mic in range(f_slice.shape[0]):\n",
    "            axs[0, i_mic].plot(freqs, f_slice[i_mic], label=\"measured\")\n",
    "            axs[0, i_mic].legend(loc=\"upper right\")\n",
    "\n",
    "            f_calibrated = f_slice[i_mic] / f_calib[i_mic]\n",
    "\n",
    "            axs[1, i_mic].plot(freqs, f_calibrated, label=\"measured\", ls=\"-\")\n",
    "            axs[1, i_mic].plot(freqs, f_theo[i_mic], label=\"theo\", color=f\"C6\", ls=\":\")\n",
    "            axs[1, i_mic].plot(\n",
    "                freqs, f_theo_corr[i_mic], label=\"theo corr\", color=\"C7\", ls=\"-.\"\n",
    "            )\n",
    "            axs[0, i_mic].set_title(f\"mic{i_mic}\")\n",
    "\n",
    "            # get probability distribution\n",
    "            valid = ~np.isnan(f_calibrated)\n",
    "            distances_bayes, proba, diff_bayes = get_probability_bayes(\n",
    "                f_calibrated[valid],\n",
    "                freqs[valid],\n",
    "                mic_idx=i_mic,\n",
    "                distance_range=distance_range,\n",
    "                sigma=1.0,\n",
    "                azimuth_deg=azimuth_deg,\n",
    "            )\n",
    "            proba = (proba - np.min(proba) + EPS) / (\n",
    "                np.max(proba) - np.min(proba) + EPS\n",
    "            )\n",
    "\n",
    "            # get probability distribution with theoretical\n",
    "            valid = np.all(~np.isnan(f_theo), axis=0)\n",
    "            distances_bayes_theo, proba_theo, diff_bayes_theo = get_probability_bayes(\n",
    "                f_theo[i_mic, valid],\n",
    "                freqs[valid],\n",
    "                mic_idx=i_mic,\n",
    "                distance_range=distance_range,\n",
    "                sigma=1.0,\n",
    "                azimuth_deg=azimuth_deg,\n",
    "            )\n",
    "            proba_theo = (proba_theo - np.min(proba_theo) + EPS) / (\n",
    "                np.max(proba_theo) - np.min(proba_theo) + EPS\n",
    "            )\n",
    "\n",
    "            valid = np.all(~np.isnan(f_theo_corr), axis=0)\n",
    "            (\n",
    "                distances_bayes_theo_corr,\n",
    "                proba_theo_corr,\n",
    "                diff_bayes_theo_corr,\n",
    "            ) = get_probability_bayes(\n",
    "                f_theo_corr[i_mic, valid],\n",
    "                freqs[valid],\n",
    "                mic_idx=i_mic,\n",
    "                distance_range=distance_range,\n",
    "                sigma=1.0,\n",
    "                azimuth_deg=azimuth_deg,\n",
    "            )\n",
    "            proba_theo_corr = (proba_theo_corr - np.min(proba_theo_corr) + EPS) / (\n",
    "                np.max(proba_theo_corr) - np.min(proba_theo_corr) + EPS\n",
    "            )\n",
    "            distance_estimators[\"measured\"].add_distribution(\n",
    "                diff_bayes * 1e-2, proba, i_mic\n",
    "            )\n",
    "            distance_estimators[\"theo\"].add_distribution(\n",
    "                diff_bayes_theo * 1e-2, proba_theo, i_mic\n",
    "            )\n",
    "            distance_estimators[\"theo_corr\"].add_distribution(\n",
    "                diff_bayes_theo_corr * 1e-2, proba_theo_corr, i_mic\n",
    "            )\n",
    "\n",
    "            axs[2, i_mic].plot(distances_bayes, proba, label=\"measured\")\n",
    "            axs[2, i_mic].plot(distances_bayes_theo, proba_theo, label=\"theo\")\n",
    "            axs[2, i_mic].plot(\n",
    "                distances_bayes_theo_corr, proba_theo_corr, label=\"theo_corr\"\n",
    "            )\n",
    "\n",
    "        for key, distance_estimator in distance_estimators.items():\n",
    "            distance_total, proba_total = distance_estimator.get_distance_distribution(\n",
    "                method=\"sum\", chosen_mics=None, azimuth_deg=azimuth_deg\n",
    "            )\n",
    "            ax_total.plot(\n",
    "                distance_total * 1e2,\n",
    "                proba_total,\n",
    "                label=f\"{key} d={nominal_distances[slice_idx]}cm\",\n",
    "                # color=f\"C{slice_idx}\",\n",
    "                ls=linestyles[key],\n",
    "            )\n",
    "\n",
    "        axs[1, i_mic].legend()\n",
    "        axs[2, i_mic].legend()\n",
    "        ax_total.legend(loc=\"upper right\")\n",
    "        ax_distance.plot(distance_corr, label=nominal_distances[slice_idx])\n",
    "\n",
    "        for i_mic in range(f_calib_all.shape[0]):\n",
    "            axs[0, i_mic].plot(freqs_calib, f_calib_all[i_mic], label=f\"calib\", ls=\":\")\n",
    "        slice_idx += 1\n",
    "\n",
    "    data_collector.fill_from_signal(\n",
    "        signals_f,\n",
    "        frequencies,\n",
    "        distance_cm=row.positions[i, 1] * 1e2,\n",
    "        time=row.seconds[i],\n",
    "    )\n",
    "\n",
    "ax_distance.legend(loc=\"upper right\")\n",
    "ax_total.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes for this experiment\n",
    "\n",
    "- apply optimization algorithm including relative distance measurements\n",
    "- do normalization over all mics rater than per-mic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Distance slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp_name = '2020_12_18_stepper'; appendix = \"\"; distance = 51\n",
    "#exp_name = '2020_12_18_flying'; appendix=\"_new\"; distance = 0\n",
    "#exp_name = '2021_03_01_flying';\n",
    "#exp_name = '2021_04_30_hover';\n",
    "exp_name = '2021_05_04_linear';\n",
    "fname = f'../experiments/{exp_name}/all_data.pkl'\n",
    "\n",
    "try:\n",
    "    df_total = pd.read_pickle(fname)\n",
    "    print('read', fname)\n",
    "except:\n",
    "    answer = input('Run wall_analysis.py to parse experiments? (y/[n])') or 'n'\n",
    "    if answer == 'y':\n",
    "        df_total = parse_experiments(exp_name)\n",
    "        pd.to_pickle(df_total, fname)\n",
    "        print('saved', fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 positions analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_positions = {\n",
    "    '_1': [20, -50, 0, 45],\n",
    "    '_2': [-20, -50, 0, -45],\n",
    "    '_3': [0, -50, 0, 0],\n",
    "    '_4': [-10, -50, 0, -30],\n",
    "    '_5': [10, -50, 0, 30],\n",
    "    '_fast1': [-20, -50, 0, -45],\n",
    "    '_fast2': [20, -50, 0, 45],\n",
    "    '_fast3': [0, -50, 0, 0],\n",
    "    '_fast4': [20, -50, 0, 30],\n",
    "    '_fast5': [-20, -50, 0, -30]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_angle(positions_rot):\n",
    "    # angles between -180, 180:\n",
    "    angles = np.arctan2(positions_rot[:30, 1]-positions_rot[0, 1], positions_rot[:30, 0]-positions_rot[0, 0]) * 180 / np.pi\n",
    "    \n",
    "    # convert 120 to 60 etc.\n",
    "    angles[angles > 90] = 180 - angles[angles > 90]\n",
    "    return np.median(angles)\n",
    "\n",
    "def get_gt_angle(row):\n",
    "    starting_yaw = starting_positions[row.appendix][3]\n",
    "    approach_angle = starting_yaw + 90\n",
    "    if approach_angle > 90:\n",
    "        approach_angle = 180 - approach_angle\n",
    "    return approach_angle\n",
    "    \n",
    "\n",
    "def plot_corrected_positions(row, max_idx=30, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    starting_pose = starting_positions[row.appendix]\n",
    "    positions_rot = np.empty_like(row.positions)\n",
    "    for j, pos in enumerate(row.positions):\n",
    "        total_yaw = starting_pose[3] + pos[3]\n",
    "        rot = R.from_euler('z', total_yaw, degrees=True)\n",
    "        pos_rot = starting_pose[:3] + rot.apply(pos[:3]) * 1e2\n",
    "        positions_rot[j, :] = np.r_[pos_rot, total_yaw]\n",
    "    \n",
    "    valid = np.all(~np.isnan(positions_rot), axis=1) & (positions_rot[:, 2] > 35)\n",
    "    positions_rot = positions_rot[valid, :]\n",
    "    average_angle = get_average_angle(positions_rot)\n",
    "    gt_angle = get_gt_angle(row)\n",
    "    ax.plot(positions_rot[:max_idx, 0], positions_rot[:max_idx, 1], color=f'C{i}', label=f'appendix {row.appendix}, {average_angle:.0f} {gt_angle:.0f}')\n",
    "    ax.axis('equal')\n",
    "    return positions_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "min_time = 0\n",
    "max_time = np.inf\n",
    "max_dist = 100 # cm\n",
    "max_idx = 30\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(5, 5)\n",
    "for i, row in df_total.iterrows():\n",
    "    fig, axs = plot_plositions(row, min_time=None, max_time=None, max_dist=None)\n",
    "    plot_corrected_positions(row, ax=ax)\n",
    "ax.legend(bbox_to_anchor=[1.0, 1.0], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 audio analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from frequency_analysis import add_spectrogram\n",
    "from plotting_tools import pcolorfast_custom\n",
    "\n",
    "df_total = df_total.assign(spectrogram=None)\n",
    "df_total = df_total.apply(add_spectrogram, axis=1)\n",
    "\n",
    "mic_idx = 0\n",
    "#maxi = np.nanmax(np.concatenate([*dfs.spectrogram], axis=1))\n",
    "for i_col, row in df_total.iterrows():\n",
    "    pass\n",
    "    #fig, ax = plot_audio(row, mic_idx=mic_idx)\n",
    "    \n",
    "    plt.figure()\n",
    "    for time_idx in range(row.frequencies_matrix.shape[0]):\n",
    "        mic_idx = 0\n",
    "        freqs = row.frequencies_matrix[time_idx, :]\n",
    "        response = np.abs(row.spectrogram[:, mic_idx, time_idx])\n",
    "        plt.plot(freqs, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "row = df_total.iloc[0] # works well 45\n",
    "#row = df_total.iloc[1] # works ok 45\n",
    "#row = df_total.iloc[2] # works well 90\n",
    "#row = df_total.iloc[3] # doesn't work 60\n",
    "#row = df_total.iloc[4] # doesn't work 60\n",
    "# fast\n",
    "#row = df_total.iloc[5] # 45\n",
    "\n",
    "positions_corr = plot_corrected_positions(row, max_idx=-1)\n",
    "plt.legend()\n",
    "plt.xlabel('x [cm]')\n",
    "plt.ylabel('y [cm]')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(row.positions[:, 1]*1e2, positions_corr[:, 1])\n",
    "plt.xlabel('relative distance [cm]')\n",
    "plt.ylabel('distance from wall [cm]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 algorithm analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import get_approach_angle_fft\n",
    "from data_collector import DataCollector\n",
    "\n",
    "n_mics = 4\n",
    "gt_angle = get_gt_angle(row)\n",
    "data_collector = DataCollector(exp_name=exp_name)\n",
    "\n",
    "for i in range(row.stft.shape[0]):\n",
    "    signals_f = row.stft[i]\n",
    "    frequencies = row.frequencies_matrix[i]\n",
    "    position = row.positions[i]\n",
    "\n",
    "    if i == row.stft.shape[0] - 1:\n",
    "        d_slice_ready = True\n",
    "        print('reached end')\n",
    "    else:\n",
    "        d_slice_ready = data_collector.next_dslice_ready(signals_f, frequencies, position*1e2, n_max=50)\n",
    "\n",
    "    if d_slice_ready:\n",
    "        d_slices, distances, stds, freqs = data_collector.get_current_distance_slice()\n",
    "        if len(distances) < 10:\n",
    "            print(f'skipping last measurement, cause only {len(distances)}')\n",
    "            break\n",
    "\n",
    "        fig, axs = plt.subplots(2, n_mics, sharey='row')\n",
    "        fig.set_size_inches(15, 5)\n",
    "        for i_mic in range(n_mics):\n",
    "            d_slice = d_slices[i_mic]\n",
    "            axs[0, i_mic].set_title(f'mic{i_mic}')\n",
    "            axs[0, i_mic].scatter(distances, d_slice, color='C0')\n",
    "            axs[0, i_mic].set_xlabel(f\"relative distance [cm]\")\n",
    "\n",
    "            #d_slice -= np.mean(d_slice, axis=1)[None, :]\n",
    "            valid = ~np.isnan(d_slice)\n",
    "            #print(distances[valid], d_slice[valid])\n",
    "            angles, proba = get_approach_angle_fft(\n",
    "                d_slice=d_slice[valid],\n",
    "                frequency=np.mean(freqs),\n",
    "                relative_distances_cm=distances[valid],\n",
    "                reduced=True\n",
    "            )\n",
    "            #EPS = 1e-10\n",
    "            #proba = (proba - np.min(proba) + EPS) / (np.max(proba) - np.min(proba) + EPS)\n",
    "            axs[1, i_mic].plot(angles, proba, color='C1')\n",
    "            axs[1, i_mic].axvline(gt_angle)\n",
    "            axs[1, i_mic].set_xlabel(\"approach angle [deg]\")\n",
    "        axs[0, 0].set_ylabel(f\"magnitude{row.appendix}\")\n",
    "        axs[1, 0].set_ylabel(f\"probability{row.appendix}\")\n",
    "\n",
    "    # only add measurements if the drone is really flying.\n",
    "    if data_collector.valid_dslice_measurement(position*1e2, signals_f, frequencies):\n",
    "        data_collector.fill_from_signal(\n",
    "            signals_f, frequencies, distance_cm=position[1]*1e2, time=row.seconds[i]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
