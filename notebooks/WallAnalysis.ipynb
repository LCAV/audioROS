{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "\n",
    "import IPython\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams[\"figure.max_open_warning\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental distance-frequency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = 'epuck'\n",
    "plot_dir = 'plots/experiments_epuck'\n",
    "\n",
    "#platform = 'crazyflie'\n",
    "#plot_dir = 'plots/experiments'\n",
    "\n",
    "# exp_name = '2021_02_09_wall_tukey';\n",
    "# exp_name = '2021_02_09_wall';\n",
    "\n",
    "exp_name = \"2021_06_08_epuck_stepper\"\n",
    "#exp_name = \"2021_02_23_wall\";  # old buzzer\n",
    "#exp_name = \"2021_02_25_wall\"; # new buzzer\n",
    "#exp_name = \"2021_04_30_stepper\"; # new hardware\n",
    "#exp_name = \"2021_03_01_flying\"\n",
    "# exp_name = '2020_12_9_rotating';\n",
    "# exp_name = '2020_11_26_wall';\n",
    "# fname = f'results/{exp_name}_real.pkl'\n",
    "\n",
    "mic_type = \"measurement\"\n",
    "#mic_type = \"audio_deck\"\n",
    "motors = 0 #\"all45000\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation import get_setup\n",
    "from plotting_tools import save_fig\n",
    "\n",
    "if platform == 'epuck':\n",
    "    from epuck_description_py import experiments, parameters\n",
    "elif platform == 'crazyflie':\n",
    "    from crazyflie_description_py import experiments, parameters\n",
    "else:\n",
    "    raise ValueError(platform)\n",
    "\n",
    "distance = 15\n",
    "yaws = np.array([0, 15, 30])\n",
    "azimuth_deg = experiments.WALL_ANGLE_DEG_STEPPER\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(5, 5)\n",
    "source, mic_positions = get_setup(distance_cm=distance, azimuth_deg=azimuth_deg-yaws[0], platform=platform)\n",
    "[ax.scatter(*mic[:2], label=f'mic{i}, $\\\\theta=${azimuth_deg-yaws[0]}$^\\\\circ$', marker='x') for i, mic in enumerate(mic_positions)]\n",
    "for yaw_deg in yaws[1:]:\n",
    "    source, mic_positions = get_setup(distance_cm=distance, azimuth_deg=azimuth_deg-yaw_deg, ax=ax, platform=platform)\n",
    "ax.set_title(f\"wall distance $d=${distance}cm and drone angles $\\\\theta$={yaws}deg\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "h_mics = {l: h for h, l in zip(handles, labels) if '\\\\theta' in l}\n",
    "l1 = ax.legend(h_mics.values(), h_mics.keys(),loc=\"lower right\", bbox_to_anchor=[.5, 0])\n",
    "\n",
    "h_other = {l: h for h, l in zip(handles, labels) if not 'mic' in l}\n",
    "ax.legend(h_other.values(), h_other.keys(),loc=\"lower left\", bbox_to_anchor=[.5, 0])\n",
    "ax.add_artist(l1)\n",
    "ax.set_xlabel(\"x [m]\")\n",
    "ax.set_ylabel(\"y [m]\")\n",
    "save_fig(fig, f'{plot_dir}/setup.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data_collector import DataCollector\n",
    "from generate_df_results import data_collector_from_df\n",
    "\n",
    "data_collector = DataCollector()\n",
    "backup_exists = data_collector.fill_from_backup(exp_name, mic_type, motors)\n",
    "if not backup_exists: \n",
    "    print('generate data using script generate_df_results.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DF analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_collector import prune_df_matrix\n",
    "\n",
    "df_matrix_raw, df_dist, df_freq_raw = data_collector.get_df_matrix()\n",
    "df_matrix, df_freq, indices = prune_df_matrix(\n",
    "    df_matrix_raw, df_freq_raw, verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from plotting_tools import add_colorbar\n",
    "\n",
    "fig, ax_all = plt.subplots()\n",
    "for mic_idx in range(df_matrix_raw.shape[0]):\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.pcolormesh(df_dist, df_freq_raw, df_matrix_raw[mic_idx])\n",
    "    ax.set_title(f\"mic{mic_idx} original\")\n",
    "    add_colorbar(fig, ax, im)\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.pcolormesh(df_dist, df_freq, df_matrix[mic_idx])\n",
    "    ax.set_title(f\"mic{mic_idx} pruned\")\n",
    "    ax_all.plot(df_freq, np.nanmean(df_matrix[mic_idx], axis=1), label=f'mic{mic_idx}')\n",
    "    add_colorbar(fig, ax, im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Distance slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from simulation import get_dist_slice_theory\n",
    "from copy import deepcopy\n",
    "from pandas_utils import fill_nans\n",
    "\n",
    "def plot_ffts(slice_exp, slice_the, dist):\n",
    "    fig_f, axs_f = plt.subplots(1, slice_exp.shape[0], squeeze=False, sharey=True)\n",
    "    fig_f.set_size_inches(10, 5)\n",
    "    fig_f.suptitle(f\"FFT of standardized distance slices, at frequency {f:.0f}Hz\")\n",
    "    for m in range(slice_exp.shape[0]):\n",
    "        slice_exp_norm = deepcopy(slice_exp[m])\n",
    "        slice_the_norm = deepcopy(slice_the[m])\n",
    "        slice_exp_norm -= np.mean(slice_exp_norm)\n",
    "        slice_the_norm -= np.mean(slice_the_norm)\n",
    "\n",
    "        n = max(len(slice_exp_norm), 1000)\n",
    "        freqs = np.fft.rfftfreq(n, d=dist[1] - dist[0])  # unit: 1/cm\n",
    "        fft_exp = np.abs(np.fft.rfft(slice_exp_norm, n=n))\n",
    "        fft_exp /= np.sum(fft_exp)\n",
    "        fft_theory = np.abs(np.fft.rfft(slice_the_norm, n=n))\n",
    "        fft_theory /= np.sum(fft_theory)\n",
    "\n",
    "        axs_f[0, m].plot(freqs, fft_theory, label=\"theoretical\")\n",
    "        axs_f[0, m].plot(freqs, fft_exp, label=\"measured\")\n",
    "        axs_f[0, m].set_title(f\"mic{m}\")\n",
    "        axs_f[0, m].legend(loc=\"upper right\")\n",
    "    return fig_f\n",
    "\n",
    "def plot_slices(slice_exp, slice_the, dist):\n",
    "    fig_f, axs_f = plt.subplots(1, slice_exp.shape[0], squeeze=False, sharey=True)\n",
    "    fig_f.set_size_inches(10, 5)\n",
    "    fig_f.suptitle(f\"Standardized distance slices, at frequency {f:.0f}Hz\")\n",
    "    for m in range(slice_exp.shape[0]):\n",
    "        slice_exp_norm = deepcopy(slice_exp[m])\n",
    "        slice_the_norm = deepcopy(slice_the[m])\n",
    "        slice_exp_norm -= np.mean(slice_exp_norm)\n",
    "        slice_the_norm -= np.mean(slice_the_norm)\n",
    "        slice_exp_norm /= np.std(slice_exp_norm)\n",
    "        slice_the_norm /= np.std(slice_the_norm)\n",
    "        \n",
    "        axs_f[0, m].plot(dist, slice_the_norm, label=\"theoretical\")\n",
    "        axs_f[0, m].plot(dist, slice_exp_norm, label=\"measured\")\n",
    "        axs_f[0, m].set_title(f\"mic{m}\")\n",
    "        axs_f[0, m].legend(loc=\"upper right\")\n",
    "    return fig_f\n",
    "\n",
    "valid_freqs = df_freq\n",
    "for i, f in enumerate(df_freq):\n",
    "    slice_exp = df_matrix[:, i, :]\n",
    "    if np.any(np.isnan(slice_exp)):\n",
    "        slice_exp = fill_nans(slice_exp, df_dist)\n",
    "    slice_the = get_dist_slice_theory(f, df_dist, azimuth_deg=experiments.WALL_ANGLE_DEG_STEPPER).T\n",
    "    \n",
    "    fig_f = plot_ffts(\n",
    "        slice_exp=slice_exp,\n",
    "        slice_the=slice_the,\n",
    "        dist=df_dist,\n",
    "    )\n",
    "    fig_d = plot_slices(\n",
    "        slice_exp=slice_exp,\n",
    "        slice_the=slice_the,\n",
    "        dist=df_dist,\n",
    "    )\n",
    "    fname = f\"{exp_name}_{motors}\"\n",
    "    save_fig(fig_d, f'{plot_dir}/{fname}_distance_slice_{f:.0f}.pdf')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from inference import get_approach_angle_fft, get_gamma_distribution, get_approach_angle_cost\n",
    "from plotting_tools import plot_performance, save_fig\n",
    "from estimators import get_estimate\n",
    "from simulation import factor_distance_to_delta\n",
    "\n",
    "azimuth_deg = experiments.WALL_ANGLE_DEG_STEPPER\n",
    "\n",
    "titles = {\n",
    "    'cost': 'optimization-based method',\n",
    "    'bayes': 'FFT-based method',\n",
    "    'bayes-combination': 'Bayesian method'\n",
    "}\n",
    "\n",
    "plot_slices = False #True\n",
    "\n",
    "d1 = df_dist[-1] # starting distance of distance slice. \n",
    "rel_movement_cm = df_dist[1]-df_dist[0]\n",
    "print(rel_movement_cm)\n",
    "factors = {mic:factor_distance_to_delta(d1, \n",
    "                                        rel_movement_cm, \n",
    "                                        mic, azimuth_deg=azimuth_deg) \n",
    "           for mic in range(4)}\n",
    "print('factors:\\n', factors)\n",
    "dN = df_dist[0] # starting distance of distance slice. \n",
    "factors_min = {mic:factor_distance_to_delta(dN, \n",
    "                                        rel_movement_cm, \n",
    "                                        mic, azimuth_deg=azimuth_deg) \n",
    "               for mic in range(4)}\n",
    "print('factors_min:\\n', factors_min)\n",
    "\n",
    "start_distances_grid = [max(df_dist) + i for i in [0, 10, 20]]\n",
    "gammas_grid = np.arange(90)\n",
    "\n",
    "factor = 2\n",
    "gt_gamma = 90 # in degrees\n",
    "\n",
    "for algo in [\"cost\", \"bayes\"]:\n",
    "    err_dict = {f\"mic{m}\": [np.nan]*len(df_freq) for m in range(df_matrix.shape[0])}\n",
    "    for i, f in enumerate(df_freq):\n",
    "        print(f)\n",
    "        d_slices = fill_nans(df_matrix[:, i, :], df_dist)\n",
    "\n",
    "        if plot_slices:\n",
    "            fig, ax = plt.subplots()\n",
    "            fig.set_size_inches(7, 5)\n",
    "        for mic_idx in range(df_matrix.shape[0]):\n",
    "            d_slice = d_slices[mic_idx]\n",
    "\n",
    "            if algo == \"bayes\":\n",
    "                ratios, prob_ratios = get_approach_angle_fft(d_slice, f, df_dist,\n",
    "                                                     n_max=1000, bayes=True, reduced=False)\n",
    "\n",
    "                gammas, prob = get_gamma_distribution(ratios, \n",
    "                                                      prob_ratios, \n",
    "                                                      factor=factor)\n",
    "                                                      #factors[mic_idx])\n",
    "            elif algo == \"cost\":\n",
    "                prob = get_approach_angle_cost(\n",
    "                    d_slice,\n",
    "                    f,\n",
    "                    df_dist,\n",
    "                    start_distances_grid,\n",
    "                    gammas_grid,\n",
    "                    mic_idx=mic_idx,\n",
    "                    azimuth_deg=azimuth_deg\n",
    "                )  # is of shape n_start_distances x n_gammas_grid\n",
    "                gammas = gammas_grid\n",
    "\n",
    "            gamma = get_estimate(gammas, prob)\n",
    "            err_dict[f\"mic{mic_idx}\"][i] = gamma - gt_gamma\n",
    "\n",
    "\n",
    "            if plot_slices:\n",
    "                ax.plot(gammas, prob)\n",
    "                ax.axvline(gamma, label=f'mic{mic_idx}: $\\\\gamma$={gamma:.1f}', color=f'C{mic_idx}')\n",
    "                #ax.plot(ratios, prob_ratios)\n",
    "                #ax.axvline(gamma, label=f'mic{mic_idx}: $\\\\gamma$={gamma:.1f}', color=f'C{mic_idx}')\n",
    "\n",
    "        if plot_slices:\n",
    "            ax.set_title(f'frequency {f:.0f}Hz')\n",
    "            ax.set_xlabel('angle of approach $\\\\gamma$ [deg]')\n",
    "            ax.set_ylabel('probability')\n",
    "            ax.legend()\n",
    "\n",
    "    fname = f\"{exp_name}_{motors}\"\n",
    "    fig, axs = plot_performance(err_dict, xs=df_freq, \n",
    "               xlabel=\"frequency [Hz]\", ylabel=\"error [deg]\")\n",
    "    axs[0, 0].grid()\n",
    "    axs[0, 0].legend(['measurement mic'])\n",
    "    fig.suptitle(titles[algo])\n",
    "    axs[0, 1].set_xlim(0,  90)\n",
    "    axs[0, 0].set_ylim(-90,  90)\n",
    "    save_fig(fig, f'{plot_dir}/{fname}_{algo}_distance_slice_performance.pdf', extension='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Frequency slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from calibration import get_calibration_function_fit\n",
    "from calibration import get_calibration_function_median\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, sharey=True)\n",
    "fig.set_size_inches(10, 5)\n",
    "calib_function_median, freqs = get_calibration_function_median(exp_name, mic_type, ax=axs[0])\n",
    "axs[0].set_title(\"calibration-individual\")\n",
    "axs[0].legend([\"measurement mic\"])\n",
    "\n",
    "calib_function_median_one, freqs = get_calibration_function_median(\n",
    "    exp_name, mic_type, ax=axs[1], fit_one_gain=True\n",
    ")\n",
    "axs[1].set_title(\"calibration-global\")\n",
    "axs[1].set_ylabel('')\n",
    "axs[1].legend().set_visible(False)\n",
    "save_fig(fig, f'{plot_dir}/{fname}_calibration_median.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation import get_df_theory\n",
    "from data_collector import normalize_df_matrix\n",
    "\n",
    "min_value = np.inf\n",
    "max_value = -np.inf\n",
    "\n",
    "chosen_mics = range(4)\n",
    "\n",
    "distances_grid = np.arange(min(df_dist), max(df_dist) + 1)\n",
    "distances_idx = np.argmin(np.abs(distances_grid[:, None] - df_dist[None, :]), axis=0)\n",
    "\n",
    "results = pd.DataFrame(columns=[\"normalization\", \"matrix\", \"values\"])\n",
    "method_dict = {\n",
    "    'raw': \"\",\n",
    "    'theoretical': \"\",\n",
    "    'calibration-individual': calib_function_median,\n",
    "    #'calibration-global': calib_function_median_one,\n",
    "    #'calibration-fit': calib_function_fit,\n",
    "    #'calibration-fit-one': calib_function_fit_one,\n",
    "    # deprecated:\n",
    "    #'calibration-online': \"calibration-online\",\n",
    "    #'standardize': \"standardize\",\n",
    "    #'zero_mean': \"zero_mean\",\n",
    "    #'normalize': \"normalize\",\n",
    "    #'calibration-offline-old': calib_function_old,\n",
    "}\n",
    "\n",
    "df_theory_pruned = get_df_theory(df_freq, df_dist, chosen_mics=chosen_mics)\n",
    "\n",
    "for j, (key, method) in enumerate(method_dict.items()):\n",
    "    values = None\n",
    "    if key == \"raw\":\n",
    "        df_norm = deepcopy(df_matrix)\n",
    "    elif key == \"theoretical\":\n",
    "        df_norm = deepcopy(df_theory_pruned[:, :, distances_idx])\n",
    "    else:\n",
    "        df_norm, values = normalize_df_matrix(\n",
    "            df_matrix=df_matrix, freqs=df_freq, method=method\n",
    "        )\n",
    "    results.loc[len(results), :] = {\n",
    "        \"normalization\": key,\n",
    "        \"matrix\": df_norm,\n",
    "        \"values\": values,\n",
    "    }\n",
    "    # print(key, data_type, df_norm.shape)\n",
    "    min_value = min(min_value, -abs(np.min(df_norm)))\n",
    "    max_value = max(max_value, abs(np.max(df_norm)))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from plotting_tools import plot_df_matrix, save_fig\n",
    "\n",
    "min_freq = min(df_freq)\n",
    "max_freq = max(df_freq)\n",
    "\n",
    "min_value = None\n",
    "max_value = None\n",
    "\n",
    "fname = f\"{exp_name}_{motors}\"\n",
    "\n",
    "for normalization, df in results.groupby(\"normalization\", sort=False):\n",
    "    matrix = df.iloc[0].matrix\n",
    "    n_mics = matrix.shape[0]\n",
    "    fig, axs = plt.subplots(1, n_mics, sharey=True, squeeze=False)\n",
    "    axs = axs[0]\n",
    "    fig.set_size_inches(n_mics*5, 5)\n",
    "    axs[0].set_ylabel('frequency [Hz]')\n",
    "    for i in range(n_mics):\n",
    "        df_exp = df.iloc[0].matrix[i]\n",
    "        ax, im = plot_df_matrix(\n",
    "            df_dist,\n",
    "            df_freq,\n",
    "            df_exp,\n",
    "            ax=axs[i],\n",
    "            min_freq=min_freq,\n",
    "            max_freq=max_freq,\n",
    "            vmin=min_value,\n",
    "            vmax=max_value,\n",
    "        )\n",
    "        ax.set_title(f\"mic{i} {normalization}\")\n",
    "        ax.set_title(f\"measurement mic {normalization}\")\n",
    "        ax.set_xlabel('distance [cm]')\n",
    "    add_colorbar(fig, ax, im)\n",
    "    #save_fig(fig, f\"plots/{fname}_matrices_{normalization}.png\")\n",
    "    \n",
    "    \n",
    "mic_idx = 0\n",
    "fig, axs = plt.subplots(1, len(method_dict), sharey=True)\n",
    "fig.set_size_inches(len(method_dict)*5, 5)\n",
    "axs[0].set_ylabel('frequency [Hz]')\n",
    "for i, (normalization, df) in enumerate(results.groupby(\"normalization\", sort=False)):\n",
    "    matrix = df.iloc[0].matrix\n",
    "    n_mics = matrix.shape[0]\n",
    "    df_exp = df.iloc[0].matrix[mic_idx]\n",
    "    ax, im = plot_df_matrix(\n",
    "        df_dist,\n",
    "        df_freq,\n",
    "        df_exp,\n",
    "        ax=axs[i],\n",
    "        min_freq=min_freq,\n",
    "        max_freq=max_freq,\n",
    "        vmin=min_value,\n",
    "        vmax=max_value,\n",
    "    )\n",
    "    ax.set_title(f\"{normalization}\")\n",
    "    ax.set_xlabel('distance [cm]')\n",
    "add_colorbar(fig, ax, im)\n",
    "save_fig(fig, f\"{plot_dir}/{fname}_matrices_mic{mic_idx}.png\", extension='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import get_probability_cost, get_probability_bayes\n",
    "from simulation import get_freq_slice_theory\n",
    "from estimators import DistanceEstimator, get_estimate\n",
    "import progressbar\n",
    "\n",
    "err_df = pd.DataFrame(columns=['method', 'mic', 'distance', 'error', 'algorithm'])\n",
    "\n",
    "distances_grid = np.arange(min(df_dist), max(df_dist))\n",
    "distances = df_dist\n",
    "mic_indices = range(df_matrix.shape[0])\n",
    "n_mics = len(mic_indices)\n",
    "\n",
    "distance_estimators = {}\n",
    "\n",
    "with progressbar.ProgressBar(max_value=len(distances)) as p:\n",
    "    for i_d, distance in enumerate(distances):\n",
    "        \n",
    "        distance_estimators = {\n",
    "            k: DistanceEstimator() for k in method_dict.keys()\n",
    "        }\n",
    "        \n",
    "        p.update(i_d)\n",
    "        for i_mic, mic_idx in enumerate(mic_indices):\n",
    "            for method, normalize_method in method_dict.items():\n",
    "                #df = results.loc[results.normalization == method]\n",
    "                \n",
    "                if method == \"theoretical\": \n",
    "                    slice_exp = get_freq_slice_theory(df_freq, distance, chosen_mics=[mic_idx], \n",
    "                                                      azimuth_deg=azimuth_deg)\n",
    "                    slice_exp = slice_exp[:, 0]\n",
    "                    std = 1\n",
    "                else:\n",
    "                    slice_exp, freqs, stds = data_collector.get_frequency_slice_fixed(\n",
    "                        df_freq, distance, mics=[mic_idx], normalize_method=normalize_method\n",
    "                    )\n",
    "                    #slice_exp, freqs, stds = data_collector.get_frequency_slice_old(\n",
    "                    #    df_freq, distance, mics=[mic_idx], normalize_method=normalize_method\n",
    "                    #)\n",
    "                    #if normalize_method != \"\":\n",
    "                    #    slice_exp = data_collector.calibrate_f_slice(slice_exp, freqs, normalize_method, mic_idx)\n",
    "                    slice_exp = slice_exp[0]\n",
    "                    std = stds[0]\n",
    "                    #plt.figure()\n",
    "                    #plt.plot(freqs, slice_exp)\n",
    "                    \n",
    "                #slice_exp = fill_nans(slice_exp, freqs)\n",
    "                proba_cost = get_probability_cost(\n",
    "                    slice_exp, freqs, \n",
    "                    distances_grid, mic_idx=mic_idx,\n",
    "                    azimuth_deg=azimuth_deg\n",
    "                )\n",
    "                distances_bayes, proba_bayes, diff_bayes = get_probability_bayes(\n",
    "                    slice_exp,\n",
    "                    freqs, \n",
    "                    mic_idx=mic_idx,\n",
    "                    distance_range=[min(distances_grid), max(distances_grid)],\n",
    "                    sigma=std,\n",
    "                    azimuth_deg=azimuth_deg\n",
    "                )\n",
    "                \n",
    "                EPS = 1e-10\n",
    "                proba_bayes_norm = (proba_bayes - np.min(proba_bayes) + EPS) / (np.max(proba_bayes) - np.min(proba_bayes) + EPS)\n",
    "                distance_estimators[method].add_distribution(\n",
    "                    diff_bayes * 1e-2, \n",
    "                    proba_bayes_norm, \n",
    "                    mic_idx\n",
    "                )\n",
    "\n",
    "                for algo, proba, distances_here in zip(\n",
    "                    [\"cost\", \"bayes\"],\n",
    "                    [proba_cost, proba_bayes],\n",
    "                    [distances_grid, distances_bayes],\n",
    "                ):\n",
    "                    d = get_estimate(distances_here, proba)\n",
    "                    err_df.loc[len(err_df), :] = {\n",
    "                        'error': d - distance,\n",
    "                        'mic': mic_idx,\n",
    "                        'distance': distance,\n",
    "                        'method': method, \n",
    "                        'algorithm': algo\n",
    "                    }\n",
    "                    \n",
    "        for method, distance_estimator in distance_estimators.items():\n",
    "            \n",
    "            # TODO(FD) remove azimuth_deg here\n",
    "            distances_here, proba = distance_estimator.get_distance_distribution(\n",
    "                method='sum', # figure out why product doesn't work\n",
    "                azimuth_deg=azimuth_deg\n",
    "            )\n",
    "            d = get_estimate(distances_here, proba) * 1e2\n",
    "            err_df.loc[len(err_df), :] = {\n",
    "                'error': d - distance,\n",
    "                'mic': 'all',\n",
    "                'distance': distance,\n",
    "                'method': method, \n",
    "                'algorithm': 'bayes-combination' \n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from plotting_tools import plot_performance\n",
    "err_df = err_df.apply(pd.to_numeric, axis=0, errors='ignore')\n",
    "\n",
    "fname = f\"{exp_name}_{motors}\"\n",
    "for key, df in err_df.groupby(\"algorithm\"):\n",
    "    for mic, df_mic in df.groupby(\"mic\"):\n",
    "        absolute_err = pd.pivot_table(df_mic, index=\"distance\", values=\"error\", columns=\"method\")\n",
    "        fig, axs = plot_performance(absolute_err, xs=distances, xlabel=\"distance [cm]\", ylabel=\"error [cm]\")\n",
    "        axs[0, 0].grid()\n",
    "        fig.suptitle(f'microphone: {mic}, {titles[key]}')\n",
    "        axs[0, 1].set_xlim(-1, max(distances))\n",
    "        \n",
    "        fname_here = f\"{plot_dir}/{fname}_{key}_mic{mic}_frequency_performance.png\"\n",
    "        save_fig(fig, fname_here, extension='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import get_probability_cost, get_probability_bayes\n",
    "from simulation import get_freq_slice_theory\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "chosen_methods = [\"raw\", \"calibration-global\", \"theoretical\"]\n",
    "#chosen_methods = method_dict.keys()\n",
    "plot_combis = [{\n",
    "    'distance': 15,\n",
    "    'algorithms': [\"bayes\"] #[\"cost\", \"bayes\"] #\"bayes-combination\"]\n",
    "}]\n",
    "    \n",
    "for plot_combi in plot_combis: \n",
    "    distance = plot_combi.get('distance')\n",
    "    algorithms = plot_combi.get('algorithms')\n",
    "    fname = f\"{exp_name}_{motors}_{distance:.0f}cm\"\n",
    "    \n",
    "    fig_slice, axs_slice = plt.subplots(len(chosen_methods), n_mics, sharex=True, sharey=True, squeeze=False)\n",
    "    fig_slice.set_size_inches(3*n_mics, 2*len(chosen_methods))\n",
    "    \n",
    "    fig_algos = {}\n",
    "    axs_algos = {}\n",
    "    for algo in algorithms:\n",
    "        fig_algo, axs_algo = plt.subplots(len(chosen_methods), n_mics, sharex=True, sharey='row', squeeze=False)\n",
    "        fig_algo.set_size_inches(3*n_mics, 2*len(chosen_methods))\n",
    "        fig_algos[algo] = fig_algo\n",
    "        axs_algos[algo] = axs_algo\n",
    "        \n",
    "    fig_combi, ax_combi = plt.subplots(len(chosen_methods), 1, squeeze=False, sharex=True)\n",
    "    \n",
    "    distance_estimators = {\n",
    "        k: DistanceEstimator() for k in chosen_methods\n",
    "    }\n",
    "    \n",
    "    for i_mic, mic_idx in enumerate(mic_indices):\n",
    "        for i_method, method in enumerate(chosen_methods):\n",
    "            \n",
    "            if method == \"theoretical\": \n",
    "                slice_exp = get_freq_slice_theory(df_freq, distance, chosen_mics=[mic_idx])\n",
    "                freqs = df_freq\n",
    "                slice_exp = slice_exp[:, 0]\n",
    "                std = 1\n",
    "            else:\n",
    "                normalize_method = method_dict[method]\n",
    "                slice_exp, freqs, stds = data_collector.get_frequency_slice_fixed(\n",
    "                    df_freq, distance, normalize_method=normalize_method, mics=[mic_idx])\n",
    "                slice_exp = slice_exp[0]\n",
    "                std = stds[0]\n",
    "                \n",
    "            #slice_exp = fill_nans(slice_exp, freqs)\n",
    "\n",
    "            # doing this here for plotting reasons. Doesn't change performance as\n",
    "            # this is done again in get_probability_cost\n",
    "            slice_exp -= np.nanmean(slice_exp)\n",
    "            slice_exp /= np.nanstd(slice_exp)\n",
    "\n",
    "            axs_slice[i_method, i_mic].plot(freqs, slice_exp, label=method, color=f\"C{i_method}\")\n",
    "            axs_slice[i_method, i_mic].set_xlim(min_freq, max_freq)\n",
    "            axs_slice[i_method, 0].set_ylabel(f'{method}')\n",
    "            axs_slice[0, i_mic].set_title(f\"mic{mic_idx}\")\n",
    "            \n",
    "            for algo in algorithms:\n",
    "                axs_algo = axs_algos[algo]\n",
    "                \n",
    "                if algo == \"cost\":\n",
    "                    proba = get_probability_cost(\n",
    "                        slice_exp, freqs, \n",
    "                        distances_grid, mic_idx=mic_idx\n",
    "                    )\n",
    "                    distances_here = distances_grid\n",
    "                elif algo == \"bayes\":\n",
    "                    distances_here, proba, diff_bayes = get_probability_bayes(\n",
    "                        slice_exp,\n",
    "                        freqs, \n",
    "                        mic_idx=mic_idx,\n",
    "                        distance_range=[min(distances_grid), max(distances_grid)],\n",
    "                        sigma=std,\n",
    "                        azimuth_deg=azimuth_deg\n",
    "                    )\n",
    "                    distance_estimators[method].add_distribution(diff_bayes * 1e-2, proba, mic_idx)\n",
    "                    \n",
    "                d = get_estimate(distances_here, proba)\n",
    "\n",
    "                axs_algo[i_method, i_mic].semilogy(distances_here, proba, color=f\"C{i_method}\")\n",
    "                axs_algo[i_method, i_mic].axvline(x=d, color=f\"C{i_method}\", label=f'estimate')\n",
    "                axs_algo[i_method, i_mic].axvline(x=distance, color=\"black\", ls=\":\", label=f'real: {distance:.0f}cm')\n",
    "                axs_algo[i_method, i_mic].set_xlim(min(distances_here)-1, max(distances_here)+1)\n",
    "                \n",
    "                axs_algo[i_method, 0].set_ylabel(f'{method}')\n",
    "            axs_algo[0, i_mic].set_title(f\"mic{mic_idx}\")\n",
    "    \n",
    "    ax_combi[0, 0].set_title('combination')\n",
    "    for i_method, (method, distance_estimator) in enumerate(distance_estimators.items()):\n",
    "        distances_m, proba = distance_estimator.get_distance_distribution(verbose=False)\n",
    "        distances_cm = distances_m * 1e2\n",
    "        ax_combi[i_method, 0].plot(distances_cm, proba, color=f\"C{i_method}\")\n",
    "        \n",
    "\n",
    "    fname_here = f'{plot_dir}/{fname}_slice.png'\n",
    "    #save_fig(fig_slice, fname_here)\n",
    "\n",
    "    for algo in algorithms:\n",
    "        axs_algos[algo][-1, -1].legend(loc='upper right')\n",
    "        #[ax.yaxis.set_major_formatter(FormatStrFormatter('%.1e')) for ax in axs_algos[algo][:, 0]]\n",
    "        fname_here = f'{plot_dir}/{fname}_{algo}.png'\n",
    "        #save_fig(fig_algos[algo], fname_here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Calibration analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibration import fit_distance_slice\n",
    "from simulation import get_amplitude_function\n",
    "\n",
    "fname = f'{exp_name}_{motors}'\n",
    "\n",
    "all_distances = data_collector.df.distance.unique()\n",
    "\n",
    "fitting_results = pd.DataFrame(\n",
    "    columns=[\"frequency\", \"mic\", \"absorption\", \"gains\", \"offset\", \"method\", \"limit_distance\"]\n",
    ")\n",
    "\n",
    "# found from below\n",
    "plot_tuples = [(0, 3093), (0, 4434), (0, 3605)]\n",
    "\n",
    "for i, (frequency, df_freq) in enumerate(data_collector.df.groupby('frequency')):\n",
    "    \n",
    "    # does not make a difference\n",
    "    # df_here = df_here[df_here.magnitude > 2]\n",
    "    distances = df_freq.distance.unique()\n",
    "    if len(distances) < len(all_distances): # only plot distances with \"full coverage\"\n",
    "        continue\n",
    "    \n",
    "    slices_median, distances_median_all, mics, stds = data_collector.get_distance_slice(frequency)\n",
    "    \n",
    "    # TODO: these don't make sense because they model the full oscillation\n",
    "    #print('stds:', stds)\n",
    "    \n",
    "    # global\n",
    "    coeffs_raw_glob, *_ =  data_collector.fit_to_raw(frequency)\n",
    "    coeffs_median_glob, *_ =  data_collector.fit_to_median(frequency)\n",
    "    \n",
    "    fitting_results.loc[len(fitting_results), :] = dict(\n",
    "        frequency=frequency,\n",
    "        mic=-1,\n",
    "        absorption=coeffs_raw_glob[0],\n",
    "        gains=coeffs_raw_glob[2],\n",
    "        offset=coeffs_raw_glob[1],\n",
    "        method=\"one-shot raw\",\n",
    "    )\n",
    "    fitting_results.loc[len(fitting_results), :] = dict(\n",
    "        frequency=frequency,\n",
    "        mic=-1,\n",
    "        absorption=coeffs_median_glob[0],\n",
    "        gains=coeffs_median_glob[2],\n",
    "        offset=coeffs_median_glob[1],\n",
    "        method=\"one-shot median\",\n",
    "    )\n",
    "        \n",
    "    for i_mic, (mic, df_here) in enumerate(df_freq.groupby('mic')):\n",
    "        mic_idx = int(mic)\n",
    "            \n",
    "        coeffs_raw, distances_raw, fit_raw, cost_raw =  data_collector.fit_to_raw(frequency, mic_idx)\n",
    "        coeffs_median, fit_median, distances_median, cost_median = data_collector.fit_to_median(frequency, mic_idx)\n",
    "        \n",
    "        # find the sigma for this frequency (per distance)\n",
    "        alpha, phase, gain = coeffs_raw\n",
    "        std_series = df_here.groupby('distance').magnitude.std()\n",
    "        std_average = np.mean(std_series.values)\n",
    "        amps = get_amplitude_function(std_series.index, \n",
    "                                      gain, \n",
    "                                      alpha, mic_idx)\n",
    "        valid_distances = std_series.index[amps >= std_average]\n",
    "        limit_distance = valid_distances[-1] if len(valid_distances) else 0\n",
    "        \n",
    "        fitting_results.loc[len(fitting_results), :] = dict(\n",
    "            frequency=frequency,\n",
    "            mic=mic_idx,\n",
    "            absorption=coeffs_median[0],\n",
    "            gains=coeffs_median[2],\n",
    "            offset=coeffs_median[1],\n",
    "            method=\"median\",\n",
    "        )\n",
    "        fitting_results.loc[len(fitting_results), :] = dict(\n",
    "            frequency=frequency,\n",
    "            mic=mic_idx,\n",
    "            absorption=coeffs_raw[0],\n",
    "            gains=coeffs_raw[2],\n",
    "            offset=coeffs_raw[1],\n",
    "            method=\"raw\",\n",
    "            limit_distance=limit_distance,\n",
    "        )\n",
    "        \n",
    "        if (mic_idx, frequency) not in plot_tuples:\n",
    "            print(mic_idx, frequency)\n",
    "            continue\n",
    "            \n",
    "        print(f'plotting: mic {mic}, frequency {frequency}, alpha={alpha:.2f}, gain={gain:.2f}')\n",
    "            \n",
    "        label = f\"{frequency:.0f}Hz\"\n",
    "        fig, axs = plt.subplots(1, 2)\n",
    "        fig.set_size_inches(10, 5)\n",
    "        \n",
    "        ax_fit, ax_freq = axs\n",
    "        \n",
    "        for d, series in df_here.groupby('distance').magnitude: \n",
    "            ax_fit.scatter([d]*len(series), series.values, color='C0', s=5.0)\n",
    "        ax_fit.scatter([], [], color='C0', s=2.0, label='raw')\n",
    "        ax_fit.plot(distances_raw, fit_raw, color='C2', label='fit to raw')\n",
    "        \n",
    "        ax_fit.plot(distances_median_all, slices_median[i_mic], color='C1', label='median')\n",
    "        #ax_fit.plot(distances_median, fit_median, color='C3', ls=':', label='fit to median')\n",
    "        \n",
    "        ax_fit.set_title('fit for ' + label)\n",
    "        ax_fit.set_ylabel('amplitude [-]')\n",
    "        ax_fit.set_xlabel('distance [cm]')\n",
    "        ax_fit.legend(loc='lower left')\n",
    "        \n",
    "        ax_freq.scatter(std_series.index, std_series.values, label=f'std', color=f'C{i}')\n",
    "        #ax_freq.axhline(stds[i_mic], label=f'average std', color=f'C{i}')\n",
    "        ax_freq.axhline(std_average, label=f'average std', color=f'C{i}')\n",
    "        #ax_freq.semilogy(std_series.index, amps*0.5, ls=':', color=f'C{i}')\n",
    "        ax_freq.semilogy(std_series.index, amps, ls=':', color=f'C{i}', label=f'amplitude')\n",
    "        #ax_freq.semilogy(std_series.index, amps*1.5, ls=':', color=f'C{i}')\n",
    "        ax_freq.set_title('magnitude vs. noise for ' + label)\n",
    "        ax_freq.legend(loc='lower left')\n",
    "        ax_freq.set_xlabel('distance [cm]')\n",
    "        #ax_freq.set_ylabel('magnitude vs. std [-]')\n",
    "        \n",
    "        fname_here = f'{plot_dir}/{fname}_fitting_{frequency:.0f}_{mic_idx}.png'\n",
    "        save_fig(fig, fname_here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(5, 5)\n",
    "df = fitting_results.loc[fitting_results.method=='raw']\n",
    "for mic, df_mic in df.groupby('mic'):\n",
    "    plt.plot(df_mic.frequency, df_mic.limit_distance, color=f'C{mic}', label=f'mic{mic}')\n",
    "    \n",
    "    success = df_mic.loc[df_mic.limit_distance == df_mic.limit_distance.max()].frequency.values\n",
    "    fail = df_mic.loc[df_mic.limit_distance < df_mic.limit_distance.max()].frequency.values\n",
    "    print(f'success mic{mic}:', success)\n",
    "    print(f'fail mic{mic}:', fail)\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('limit distance [cm]')\n",
    "plt.legend()\n",
    "fname_here = f'{plot_dir}/{fname}_limit_distance.png'\n",
    "save_fig(fig, fname_here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "color_palette = \"tab10\"\n",
    "extra_kwargs = {\n",
    "    \"linewidth\": 0,\n",
    "    \"palette\": color_palette,\n",
    "    \"style\": \"method\",\n",
    "    \"hue\": \"mic\",\n",
    "    \"data\": fitting_results,\n",
    "    \"x\": \"frequency\",\n",
    "}\n",
    "palette = sns.palettes.color_palette(color_palette)\n",
    "fitting_results = fitting_results.apply(pd.to_numeric, errors=\"ignore\", axis=0)\n",
    "plt.figure()\n",
    "sns.scatterplot(\n",
    "    y=\"gains\", **extra_kwargs,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "sns.scatterplot(y=\"absorption\", **extra_kwargs)\n",
    "\n",
    "plt.figure()\n",
    "sns.scatterplot(y=\"offset\", **extra_kwargs)\n",
    "plt.ylabel(\"offset [cm]\")\n",
    "\n",
    "ls = {\"one-shot raw\": \"-\", \"median\": \":\", \"one-shot median\": \"--\", \"raw\": \"-.\"}\n",
    "for method, df in fitting_results.groupby(\"method\"):\n",
    "    medians = df.groupby([\"mic\"]).offset.median()\n",
    "    [plt.axhline(m, color=palette[i], ls=ls[method]) for i, m in enumerate(medians)]\n",
    "    plt.plot([], [], color=\"black\", ls=ls[method], label=method)\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282.883px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
