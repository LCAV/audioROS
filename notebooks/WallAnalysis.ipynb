{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "\n",
    "import IPython\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams[\"figure.max_open_warning\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation import get_setup\n",
    "\n",
    "distance = 15\n",
    "azimuths = [0, 15, 30]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(5, 5)\n",
    "source, mic_positions = get_setup(distance_cm=distance, azimuth_deg=azimuths[0])\n",
    "[ax.scatter(*mic[:2], label=f'mic{i}, $\\\\theta=${azimuths[0]}$^\\\\circ$', marker='x') for i, mic in enumerate(mic_positions)]\n",
    "for azimuth_deg in azimuths[1:]:\n",
    "    source, mic_positions = get_setup(distance_cm=distance, azimuth_deg=azimuth_deg, ax=ax)\n",
    "ax.set_title(f\"wall distance $d=${distance}cm and angle $\\\\theta$={azimuths}deg\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "h_mics = {l: h for h, l in zip(handles, labels) if '\\\\theta' in l}\n",
    "l1 = ax.legend(h_mics.values(), h_mics.keys(),loc=\"lower right\", bbox_to_anchor=[.5, 0])\n",
    "\n",
    "h_other = {l: h for h, l in zip(handles, labels) if not 'mic' in l}\n",
    "ax.legend(h_other.values(), h_other.keys(),loc=\"lower left\", bbox_to_anchor=[.5, 0])\n",
    "ax.add_artist(l1)\n",
    "ax.set_xlabel(\"x [m]\")\n",
    "ax.set_ylabel(\"y [m]\")\n",
    "fig.savefig(f'plots/setup.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental distance-frequency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_name = '2021_02_09_wall_tukey';\n",
    "# exp_name = '2021_02_09_wall';\n",
    "\n",
    "exp_name = \"2021_02_23_wall\";  # old buzzer\n",
    "#exp_name = \"2021_02_25_wall\"; # new buzzer\n",
    "#exp_name = \"2021_03_01_flying\"\n",
    "# exp_name = '2020_12_9_rotating';\n",
    "# exp_name = '2020_11_26_wall';\n",
    "# fname = f'results/{exp_name}_real.pkl'\n",
    "\n",
    "mic_type = \"audio_deck\"\n",
    "motors = 0 #\"all45000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from wall_detector import WallDetector\n",
    "from generate_df_results import wall_detector_from_df\n",
    "\n",
    "wall_detector = WallDetector()\n",
    "backup_exists = wall_detector.fill_from_backup(exp_name, mic_type, motors)\n",
    "if not backup_exists: \n",
    "    print('generate data using script generate_df_results.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_detector.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wall_detector import prune_df_matrix\n",
    "\n",
    "df_matrix_raw, df_dist, df_freq_raw = wall_detector.get_df_matrix()\n",
    "df_matrix, df_freq, indices = prune_df_matrix(\n",
    "    df_matrix_raw, df_freq_raw, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting_tools import add_colorbar\n",
    "\n",
    "fig, ax_all = plt.subplots()\n",
    "for mic_idx in range(4):\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.pcolormesh(df_dist, df_freq_raw, df_matrix_raw[mic_idx])\n",
    "    ax.set_title(f\"mic{mic_idx} original\")\n",
    "    add_colorbar(fig, ax, im)\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.pcolormesh(df_dist, df_freq, df_matrix[mic_idx])\n",
    "    ax.set_title(f\"mic{mic_idx} pruned\")\n",
    "    ax_all.plot(df_freq, np.nanmean(df_matrix[mic_idx], axis=1), label=f'mic{mic_idx}')\n",
    "    add_colorbar(fig, ax, im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. study distance slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from simulation import get_dist_slice_theory\n",
    "from copy import deepcopy\n",
    "from pandas_utils import fill_nans\n",
    "\n",
    "def plot_ffts(slice_exp, slice_the, dist):\n",
    "    fig_f, axs_f = plt.subplots(1, slice_exp.shape[0], squeeze=False, sharey=True)\n",
    "    fig_f.set_size_inches(10, 5)\n",
    "    fig_f.suptitle(f\"FFT of standardized distance slices, at frequency {f:.0f}Hz\")\n",
    "    for m in range(slice_exp.shape[0]):\n",
    "        slice_exp_norm = deepcopy(slice_exp[m])\n",
    "        slice_the_norm = deepcopy(slice_the[m])\n",
    "        slice_exp_norm -= np.mean(slice_exp_norm)\n",
    "        slice_the_norm -= np.mean(slice_the_norm)\n",
    "\n",
    "        n = max(len(slice_exp_norm), 1000)\n",
    "        freqs = np.fft.rfftfreq(n, d=dist[1] - dist[0])  # unit: 1/cm\n",
    "        fft_exp = np.abs(np.fft.rfft(slice_exp_norm, n=n))\n",
    "        fft_exp /= np.sum(fft_exp)\n",
    "        fft_theory = np.abs(np.fft.rfft(slice_the_norm, n=n))\n",
    "        fft_theory /= np.sum(fft_theory)\n",
    "\n",
    "        axs_f[0, m].plot(freqs, fft_theory, label=\"theoretical\")\n",
    "        axs_f[0, m].plot(freqs, fft_exp, label=\"measured\")\n",
    "        axs_f[0, m].set_title(f\"mic{m}\")\n",
    "        axs_f[0, m].legend(loc=\"upper right\")\n",
    "    return fig_f\n",
    "\n",
    "valid_freqs = df_freq\n",
    "for i, f in enumerate(df_freq):\n",
    "    slice_exp = df_matrix[:, i, :]\n",
    "    if np.any(np.isnan(slice_exp)):\n",
    "        slice_exp = fill_nans(slice_exp, df_dist)\n",
    "    slice_the = get_dist_slice_theory(f, df_dist).T\n",
    "    \n",
    "    fig_f = plot_ffts(\n",
    "        slice_exp=slice_exp,\n",
    "        slice_the=slice_the,\n",
    "        dist=df_dist,\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation import factor_distance_to_delta\n",
    "\n",
    "for mic in range(4):\n",
    "    print('mic', mic)\n",
    "    for distance in np.arange(10, 50, step=10):\n",
    "        f = factor_distance_to_delta(distance, mic)\n",
    "        print(distance, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance slice algorithm\n",
    "from inference import get_approach_angle_fft, get_gamma_distribution\n",
    "from plotting_tools import plot_performance, save_fig\n",
    "from estimators import get_estimate\n",
    "\n",
    "EPS = 1e-10\n",
    "gt_gamma = 90 # in degrees\n",
    "err_dict = {f\"mic{m}\": [np.nan]*len(df_freq) for m in range(df_matrix.shape[0])}\n",
    "for i, f in enumerate(df_freq):\n",
    "    \n",
    "    d_slices = fill_nans(df_matrix[:, i, :], df_dist)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(7, 5)\n",
    "    for mic_idx in range(df_matrix.shape[0]):\n",
    "        d_slice = d_slices[mic_idx]\n",
    "        ratios, prob = get_approach_angle_fft(d_slice, f, df_dist,\n",
    "                                             n_max=1000, bayes=False, reduced=False)\n",
    "        gammas, prob = get_gamma_distribution(ratios, prob, factor=1.9)\n",
    "        gamma = get_estimate(gammas, prob)\n",
    "        \n",
    "        ax.plot(gammas, prob)\n",
    "        ax.axvline(gamma, label=f'mic{mic_idx}: $\\\\gamma$={gamma:.1f}', color=f'C{mic_idx}')\n",
    "        err_dict[f\"mic{mic_idx}\"][i] = gamma - gt_gamma\n",
    "        \n",
    "    ax.set_title(f'frequency {f:.0f}Hz')\n",
    "    ax.set_xlabel('angle of approach $\\\\gamma$ [deg]')\n",
    "    ax.set_ylabel('probability')\n",
    "    ax.legend()\n",
    "        \n",
    "fname = f\"{exp_name}_{motors}\"\n",
    "fig, axs = plot_performance(err_dict, xs=df_freq, \n",
    "           xlabel=\"frequency [Hz]\", ylabel=\"error [deg]\")\n",
    "save_fig(fig, f'plots/{fname}_distance_slice_performance.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. study full matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from calibration import get_calibration_function_fit\n",
    "from calibration import get_calibration_function_median\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "calib_function_median = get_calibration_function_median(exp_name, mic_type, ax=ax)\n",
    "ax.set_title(\"median\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "calib_function_median_one = get_calibration_function_median(\n",
    "    exp_name, mic_type, ax=ax, fit_one_gain=True\n",
    ")\n",
    "ax.set_title(\"median one\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "calib_function_fit = get_calibration_function_fit(exp_name, mic_type, ax=ax)\n",
    "ax.set_title(\"fit\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "calib_function_fit_one = get_calibration_function_fit(\n",
    "    exp_name, mic_type, ax=ax, fit_one_gain=True\n",
    ")\n",
    "ax.set_title(\"fit one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation import get_df_theory\n",
    "from wall_detector import normalize_df_matrix\n",
    "\n",
    "min_value = np.inf\n",
    "max_value = -np.inf\n",
    "\n",
    "chosen_mics = range(4)\n",
    "\n",
    "distances_grid = np.arange(min(df_dist), max(df_dist) + 1)\n",
    "distances_idx = np.argmin(np.abs(distances_grid[:, None] - df_dist[None, :]), axis=0)\n",
    "\n",
    "results = pd.DataFrame(columns=[\"normalization\", \"matrix\", \"values\"])\n",
    "method_dict = {\n",
    "    'raw': \"\",\n",
    "    'theoretical': \"\",\n",
    "    'calibration-median': calib_function_median,\n",
    "    'calibration-median-one': calib_function_median_one,\n",
    "    'calibration-fit': calib_function_fit,\n",
    "    'calibration-fit-one': calib_function_fit_one,\n",
    "    #'calibration-online': \"calibration-online\",\n",
    "    #'standardize': \"standardize\",\n",
    "    #'zero_mean': \"zero_mean\",\n",
    "    #'normalize': \"normalize\",\n",
    "    #'calibration-offline-old': calib_function_old,\n",
    "}\n",
    "\n",
    "df_theory_pruned = get_df_theory(df_freq, df_dist, chosen_mics=chosen_mics)\n",
    "\n",
    "for j, (key, method) in enumerate(method_dict.items()):\n",
    "    values = None\n",
    "    if key == \"raw\":\n",
    "        df_norm = deepcopy(df_matrix)\n",
    "    elif key == \"theoretical\":\n",
    "        df_norm = deepcopy(df_theory_pruned[:, :, distances_idx])\n",
    "    else:\n",
    "        df_norm, values = normalize_df_matrix(\n",
    "            df_matrix=df_matrix, freqs=df_freq, method=method\n",
    "        )\n",
    "    results.loc[len(results), :] = {\n",
    "        \"normalization\": key,\n",
    "        \"matrix\": df_norm,\n",
    "        \"values\": values,\n",
    "    }\n",
    "    # print(key, data_type, df_norm.shape)\n",
    "    min_value = min(min_value, -abs(np.min(df_norm)))\n",
    "    max_value = max(max_value, abs(np.max(df_norm)))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from plotting_tools import plot_df_matrix, save_fig\n",
    "\n",
    "min_freq = min(df_freq)\n",
    "max_freq = max(df_freq)\n",
    "\n",
    "min_value = None\n",
    "max_value = None\n",
    "\n",
    "fname = f\"{exp_name}_{motors}\"\n",
    "\n",
    "for normalization, df in results.groupby(\"normalization\", sort=False):\n",
    "    matrix = df.iloc[0].matrix\n",
    "    n_mics = matrix.shape[0]\n",
    "    fig, axs = plt.subplots(1, n_mics, sharey=True)\n",
    "    fig.set_size_inches(n_mics*5, 5)\n",
    "    axs[0].set_ylabel('frequency [Hz]')\n",
    "    for i in range(n_mics):\n",
    "        df_exp = df.iloc[0].matrix[i]\n",
    "        ax, im = plot_df_matrix(\n",
    "            df_dist,\n",
    "            df_freq,\n",
    "            df_exp,\n",
    "            ax=axs[i],\n",
    "            min_freq=min_freq,\n",
    "            max_freq=max_freq,\n",
    "            vmin=min_value,\n",
    "            vmax=max_value,\n",
    "        )\n",
    "        ax.set_title(f\"mic{i} {normalization}\")\n",
    "        ax.set_xlabel('distance [cm]')\n",
    "    add_colorbar(fig, ax, im)\n",
    "    save_fig(fig, f\"plots/{fname}_matrices_{normalization}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluate algorithm performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_method = \"calibration-fit\"\n",
    "method = method_dict[normalize_method]\n",
    "matrix = results.loc[results.normalization == normalize_method].iloc[0].matrix\n",
    "\n",
    "distance = 10\n",
    "mic_idx = 1\n",
    "freq_slice = matrix[mic_idx, :, distance]\n",
    "plt.figure()\n",
    "plt.plot(df_freq, freq_slice)\n",
    "\n",
    "noisy_freq = df_freq + np.random.normal(scale=20, size=len(df_freq))\n",
    "freq_slice_raw, used_freq, stds = wall_detector.get_frequency_slice_fixed(\n",
    "    noisy_freq, distance=distance, normalize_method=method, mics=[mic_idx], verbose=True\n",
    ")\n",
    "plt.plot(used_freq, freq_slice_raw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import get_probability_cost, get_probability_bayes\n",
    "from simulation import get_freq_slice_theory\n",
    "from estimators import DistanceEstimator, get_estimate\n",
    "import progressbar\n",
    "\n",
    "err_df = pd.DataFrame(columns=['method', 'mic', 'distance', 'error', 'algorithm'])\n",
    "\n",
    "distances_grid = np.arange(min(df_dist), max(df_dist))\n",
    "distances = df_dist\n",
    "mic_indices = range(4)\n",
    "n_mics = len(mic_indices)\n",
    "\n",
    "distance_estimators = {}\n",
    "\n",
    "with progressbar.ProgressBar(max_value=len(distances)) as p:\n",
    "    for i_d, distance in enumerate(distances):\n",
    "        \n",
    "        distance_estimators = {\n",
    "            k: DistanceEstimator() for k in method_dict.keys()\n",
    "        }\n",
    "        \n",
    "        p.update(i_d)\n",
    "        for i_mic, mic_idx in enumerate(mic_indices):\n",
    "            for method, normalize_method in method_dict.items():\n",
    "                #df = results.loc[results.normalization == method]\n",
    "                \n",
    "                if method == \"theoretical\": \n",
    "                    freqs = wall_detector.df[wall_detector.df.distance==distance].frequency.unique()\n",
    "                    slice_exp = get_freq_slice_theory(freqs, distance, chosen_mics=[mic_idx])\n",
    "                    slice_exp = slice_exp[:, 0]\n",
    "                    std = 1\n",
    "                else:\n",
    "                    #slice_exp, freqs, stds = wall_detector.get_frequency_slice(\n",
    "                    #    distance, normalize_method=normalize_method, mics=[mic_idx])\n",
    "                    slice_exp, freqs, stds = wall_detector.get_frequency_slice_fixed(\n",
    "                        df_freq, distance, normalize_method=normalize_method, mics=[mic_idx])\n",
    "                    slice_exp = slice_exp[0]\n",
    "                    std = stds[0]\n",
    "                    \n",
    "                    #matrix_exp = results.loc[results.normalization==method].iloc[0].matrix\n",
    "                    #slice_exp = matrix_exp[i_mic, :, i_d]\n",
    "                    #freqs = df_freq\n",
    "                #slice_exp = fill_nans(slice_exp, freqs)\n",
    "\n",
    "                proba_cost = get_probability_cost(\n",
    "                    slice_exp, freqs, \n",
    "                    distances_grid, mic_idx=mic_idx\n",
    "                )\n",
    "                distances_bayes, proba_bayes, diff_bayes = get_probability_bayes(\n",
    "                    slice_exp,\n",
    "                    freqs, \n",
    "                    mic_idx=mic_idx,\n",
    "                    distance_range=[min(distances_grid), max(distances_grid)],\n",
    "                    sigma=std\n",
    "                )\n",
    "                \n",
    "                distance_estimators[method].add_distribution(diff_bayes * 1e-2, proba_bayes, mic_idx)\n",
    "\n",
    "                for algo, proba, distances_here in zip(\n",
    "                    [\"cost\", \"bayes\"],\n",
    "                    [proba_cost, proba_bayes],\n",
    "                    [distances_grid, distances_bayes],\n",
    "                ):\n",
    "                    d = get_estimate(distances_here, proba)\n",
    "                    err_df.loc[len(err_df), :] = {\n",
    "                        'error': d - distance,\n",
    "                        'mic': mic_idx,\n",
    "                        'distance': distance,\n",
    "                        'method': method, \n",
    "                        'algorithm': algo\n",
    "                    }\n",
    "                    \n",
    "        for method, distance_estimator in distance_estimators.items():\n",
    "            distances_here, proba = distance_estimator.get_distance_distribution()\n",
    "            d = get_estimate(distances_here, proba)\n",
    "            err_df.loc[len(err_df), :] = {\n",
    "                'error': d - distance,\n",
    "                'mic': -1,\n",
    "                'distance': distance,\n",
    "                'method': method, \n",
    "                'algorithm': 'bayes-combination' \n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting_tools import plot_performance\n",
    "titles = {\n",
    "    'cost': 'optimization-based method',\n",
    "    'bayes': 'FFT-based method',\n",
    "    'bayes-combination': 'combination'\n",
    "}\n",
    "err_df = err_df.apply(pd.to_numeric, axis=0, errors='ignore')\n",
    "\n",
    "fname = f\"{exp_name}_{motors}\"\n",
    "for key, df in err_df.groupby(\"algorithm\"):\n",
    "    for mic, df_mic in df.groupby(\"mic\"):\n",
    "        absolute_err = pd.pivot_table(df_mic, index=\"distance\", values=\"error\", columns=\"method\")\n",
    "        fig, axs = plot_performance(absolute_err, xs=distances, xlabel=\"distance [cm]\", ylabel=\"absolute error [cm]\")\n",
    "        axs[0, 0].grid()\n",
    "        #axs[0, 0].set_title(f'mic{mic}, {titles[key]}')\n",
    "        #axs[0, 1].set_title(f'mic{mic}, {titles[key]}')\n",
    "        fig.suptitle(f'mic{mic}, {titles[key]}')\n",
    "        axs[0, 1].set_xlim(-1, max(distances))\n",
    "        \n",
    "        fname_here = f\"plots/{fname}_{key}_mic{mic}_frequency_performance.png\"\n",
    "        save_fig(fig, fname_here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import get_probability_cost, get_probability_bayes\n",
    "from simulation import get_freq_slice_theory\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "mic_idx = 1\n",
    "\n",
    "chosen_methods = [\"raw\", \"calibration-median\", \"theoretical\"]\n",
    "#chosen_methods = method_dict.keys()\n",
    "plot_combis = [{\n",
    "    'distance': 11,\n",
    "    'algorithms': [\"cost\", \"bayes\"]\n",
    "}]\n",
    "    \n",
    "for plot_combi in plot_combis: \n",
    "    distance = plot_combi.get('distance')\n",
    "    algorithms = plot_combi.get('algorithms')\n",
    "    fname = f\"{exp_name}_{motors}_{distance:.0f}cm\"\n",
    "    \n",
    "    fig_slice, axs_slice = plt.subplots(len(chosen_methods), n_mics, sharex=True, sharey=True)\n",
    "    fig_slice.set_size_inches(3*n_mics, 2*len(chosen_methods))\n",
    "    \n",
    "    fig_algos = {}\n",
    "    axs_algos = {}\n",
    "    for algo in algorithms:\n",
    "        fig_algo, axs_algo = plt.subplots(len(chosen_methods), n_mics, sharex=True, sharey='row')\n",
    "        fig_algo.set_size_inches(3*n_mics, 2*len(chosen_methods))\n",
    "        fig_algos[algo] = fig_algo\n",
    "        axs_algos[algo] = axs_algo\n",
    "    \n",
    "    for i_mic, mic_idx in enumerate(mic_indices):\n",
    "        for i_method, method in enumerate(chosen_methods):\n",
    "            df = results.loc[results.normalization == method]\n",
    "            if method == \"theoretical\": \n",
    "                freqs = np.sort(wall_detector.df[wall_detector.df.distance==distance].frequency.unique())\n",
    "                slice_exp = get_freq_slice_theory(freqs, distance)\n",
    "                slice_exp = slice_exp.T\n",
    "                stds = [1]*slice_exp.shape[0]\n",
    "            else:\n",
    "                normalize_method = method_dict[method]\n",
    "                slice_exp, freqs, stds = wall_detector.get_frequency_slice(\n",
    "                    distance, normalize_method=normalize_method)\n",
    "\n",
    "            slice_exp = fill_nans(slice_exp, freqs)\n",
    "            slice_exp = slice_exp[mic_idx]\n",
    "\n",
    "            # doing this here for plotting reasons. Doesn't change performance as\n",
    "            # this is done again in get_probability_cost\n",
    "            slice_exp -= np.nanmean(slice_exp)\n",
    "            slice_exp /= np.nanstd(slice_exp)\n",
    "\n",
    "            axs_slice[i_method, i_mic].plot(freqs, slice_exp, label=method, color=f\"C{i_method}\")\n",
    "            axs_slice[i_method, i_mic].set_xlim(min_freq, max_freq)\n",
    "            axs_slice[i_method, 0].set_ylabel(f'{method}')\n",
    "            axs_slice[0, i_mic].set_title(f\"mic{mic_idx}\")\n",
    "            \n",
    "            for algo in algorithms:\n",
    "                axs_algo = axs_algos[algo]\n",
    "                \n",
    "                if algo == \"cost\":\n",
    "                    proba = get_probability_cost(\n",
    "                        slice_exp, freqs, \n",
    "                        distances_grid, mic_idx=mic_idx\n",
    "                    )\n",
    "                    distances_here = distances_grid\n",
    "                elif algo == \"bayes\":\n",
    "                    distances_here, proba, diff = get_probability_bayes(\n",
    "                        slice_exp,\n",
    "                        freqs, \n",
    "                        mic_idx=mic_idx,\n",
    "                        distance_range=[min(distances_grid), max(distances_grid)],\n",
    "                        sigma=stds[mic_idx]\n",
    "                    )\n",
    "\n",
    "                d_idx = np.argmax(proba)\n",
    "                d = distances_here[d_idx]\n",
    "\n",
    "                axs_algo[i_method, i_mic].semilogy(distances_here, proba, color=f\"C{i_method}\")\n",
    "                axs_algo[i_method, i_mic].axvline(x=d, color=f\"C{i_method}\", label=f'estimate')\n",
    "                axs_algo[i_method, i_mic].axvline(x=distance, color=\"black\", ls=\":\", label=f'real: {distance:.0f}cm')\n",
    "                axs_algo[i_method, i_mic].set_xlim(min(distances_here)-1, max(distances_here)+1)\n",
    "\n",
    "                axs_algo[0, i_mic].set_title(f\"mic{mic_idx}\")\n",
    "                axs_algo[i_method, 0].set_ylabel(f'{method}')\n",
    "\n",
    "    fname_here = f'plots/{fname}_slice.png'\n",
    "    save_fig(fig_slice, fname_here)\n",
    "\n",
    "    for algo in algorithms:\n",
    "        axs_algos[algo][-1, -1].legend(loc='upper right')\n",
    "        fname_here = f'plots/{fname}_{algo}.png'\n",
    "        save_fig(fig_algos[algo], fname_here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibration import fit_distance_slice\n",
    "from simulation import get_amplitude_function\n",
    "\n",
    "fname = f'{exp_name}_{motors}'\n",
    "\n",
    "all_distances = wall_detector.df.distance.unique()\n",
    "\n",
    "fitting_results = pd.DataFrame(\n",
    "    columns=[\"frequency\", \"mic\", \"absorption\", \"gains\", \"offset\", \"method\", \"limit_distance\"]\n",
    ")\n",
    "\n",
    "# found from below\n",
    "plot_tuples = [(0, 3093), (0, 3218), (3, 3734)]\n",
    "\n",
    "for i, (frequency, df_freq) in enumerate(wall_detector.df.groupby('frequency')):\n",
    "    \n",
    "    # does not make a difference\n",
    "    # df_here = df_here[df_here.magnitude > 2]\n",
    "    distances = df_freq.distance.unique()\n",
    "    if len(distances) < len(all_distances): # only plot distances with \"full coverage\"\n",
    "        continue\n",
    "    \n",
    "    slices_median, distances_median_all, mics, stds = wall_detector.get_distance_slice(frequency, method=np.nanmedian)\n",
    "    \n",
    "    # TODO: these don't make sense because they model the full oscillation\n",
    "    #print('stds:', stds)\n",
    "    \n",
    "    # global\n",
    "    coeffs_raw_glob, *_ =  wall_detector.fit_to_raw(frequency)\n",
    "    coeffs_median_glob, *_ =  wall_detector.fit_to_median(frequency)\n",
    "    \n",
    "    fitting_results.loc[len(fitting_results), :] = dict(\n",
    "        frequency=frequency,\n",
    "        mic=-1,\n",
    "        absorption=coeffs_raw_glob[0],\n",
    "        gains=coeffs_raw_glob[2],\n",
    "        offset=coeffs_raw_glob[1],\n",
    "        method=\"one-shot raw\",\n",
    "    )\n",
    "    fitting_results.loc[len(fitting_results), :] = dict(\n",
    "        frequency=frequency,\n",
    "        mic=-1,\n",
    "        absorption=coeffs_median_glob[0],\n",
    "        gains=coeffs_median_glob[2],\n",
    "        offset=coeffs_median_glob[1],\n",
    "        method=\"one-shot median\",\n",
    "    )\n",
    "        \n",
    "    for i_mic, (mic, df_here) in enumerate(df_freq.groupby('mic')):\n",
    "        mic_idx = int(mic)\n",
    "            \n",
    "        coeffs_raw, distances_raw, fit_raw, cost_raw =  wall_detector.fit_to_raw(frequency, mic_idx)\n",
    "        coeffs_median, fit_median, distances_median, cost_median =  wall_detector.fit_to_median(frequency, mic_idx)\n",
    "        \n",
    "        # find the sigma for this frequency (per distance)\n",
    "        alpha, phase, gain = coeffs_raw\n",
    "        std_series = df_here.groupby('distance').magnitude.std()\n",
    "        std_average = np.mean(std_series.values)\n",
    "        amps = get_amplitude_function(std_series.index, \n",
    "                                      gain, \n",
    "                                      alpha, mic_idx)\n",
    "        valid_distances = std_series.index[amps >= std_average]\n",
    "        limit_distance = valid_distances[-1] if len(valid_distances) else 0\n",
    "        \n",
    "        fitting_results.loc[len(fitting_results), :] = dict(\n",
    "            frequency=frequency,\n",
    "            mic=mic_idx,\n",
    "            absorption=coeffs_median[0],\n",
    "            gains=coeffs_median[2],\n",
    "            offset=coeffs_median[1],\n",
    "            method=\"median\",\n",
    "        )\n",
    "        fitting_results.loc[len(fitting_results), :] = dict(\n",
    "            frequency=frequency,\n",
    "            mic=mic_idx,\n",
    "            absorption=coeffs_raw[0],\n",
    "            gains=coeffs_raw[2],\n",
    "            offset=coeffs_raw[1],\n",
    "            method=\"raw\",\n",
    "            limit_distance=limit_distance,\n",
    "        )\n",
    "        \n",
    "        if (mic_idx, frequency) not in plot_tuples:\n",
    "            continue\n",
    "            \n",
    "        print(f'plotting: mic {mic}, frequency {frequency}, alpha={alpha:.2f}, gain={gain:.2f}')\n",
    "            \n",
    "        label = f\"{frequency:.0f}Hz\"\n",
    "        fig, axs = plt.subplots(1, 2)\n",
    "        fig.set_size_inches(10, 5)\n",
    "        \n",
    "        ax_fit, ax_freq = axs\n",
    "        \n",
    "        for d, series in df_here.groupby('distance').magnitude: \n",
    "            ax_fit.scatter([d]*len(series), series.values, color='C0', s=5.0)\n",
    "        ax_fit.scatter([], [], color='C0', s=2.0, label='raw')\n",
    "        ax_fit.plot(distances_raw, fit_raw, color='C2', label='fit to raw')\n",
    "        \n",
    "        ax_fit.plot(distances_median_all, slices_median[i_mic], color='C1', label='median')\n",
    "        ax_fit.plot(distances_median, fit_median, color='C3', ls=':', label='fit to median')\n",
    "        \n",
    "        ax_fit.set_title(label)\n",
    "        ax_fit.set_ylabel('amplitude [-]')\n",
    "        ax_fit.set_xlabel('distance [cm]')\n",
    "        ax_fit.legend(loc='upper right')\n",
    "        \n",
    "        ax_freq.scatter(std_series.index, std_series.values, label=f'std', color=f'C{i}')\n",
    "        #ax_freq.axhline(stds[i_mic], label=f'average std', color=f'C{i}')\n",
    "        ax_freq.axhline(std_average, label=f'average std', color=f'C{i}')\n",
    "        ax_freq.semilogy(std_series.index, amps*0.5, ls=':', color=f'C{i}')\n",
    "        ax_freq.semilogy(std_series.index, amps, ls=':', color=f'C{i}', label=f'amplitude')\n",
    "        ax_freq.semilogy(std_series.index, amps*1.5, ls=':', color=f'C{i}')\n",
    "        ax_freq.set_title(label)\n",
    "        ax_freq.legend(loc='upper right')\n",
    "        ax_freq.set_xlabel('distance [cm]')\n",
    "        ax_freq.set_ylabel('magnitude vs. std [-]')\n",
    "        \n",
    "        fname_here = f'plots/{fname}_fitting_{frequency:.0f}_{mic_idx}.png'\n",
    "        save_fig(fig, fname_here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(5, 5)\n",
    "df = fitting_results.loc[fitting_results.method=='raw']\n",
    "for mic, df_mic in df.groupby('mic'):\n",
    "    plt.plot(df_mic.frequency, df_mic.limit_distance, color=f'C{mic}', label=f'mic{mic}')\n",
    "    \n",
    "    success = df_mic.loc[df_mic.limit_distance == df_mic.limit_distance.max()].frequency.values\n",
    "    fail = df_mic.loc[df_mic.limit_distance < df_mic.limit_distance.max()].frequency.values\n",
    "    print(f'success mic{mic}:', success)\n",
    "    print(f'fail mic{mic}:', fail)\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('limit distance [cm]')\n",
    "plt.legend()\n",
    "fname_here = f'plots/{fname}_limit_distance.png'\n",
    "save_fig(fig, fname_here)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "color_palette = \"tab10\"\n",
    "extra_kwargs = {\n",
    "    \"linewidth\": 0,\n",
    "    \"palette\": color_palette,\n",
    "    \"style\": \"method\",\n",
    "    \"hue\": \"mic\",\n",
    "    \"data\": fitting_results,\n",
    "    \"x\": \"frequency\",\n",
    "}\n",
    "palette = sns.palettes.color_palette(color_palette)\n",
    "fitting_results = fitting_results.apply(pd.to_numeric, errors=\"ignore\", axis=0)\n",
    "plt.figure()\n",
    "sns.scatterplot(\n",
    "    y=\"gains\", **extra_kwargs,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "sns.scatterplot(y=\"absorption\", **extra_kwargs)\n",
    "\n",
    "plt.figure()\n",
    "sns.scatterplot(y=\"offset\", **extra_kwargs)\n",
    "plt.ylabel(\"offset [cm]\")\n",
    "\n",
    "ls = {\"one-shot raw\": \"-\", \"median\": \":\", \"one-shot median\": \"--\", \"raw\": \"-.\"}\n",
    "for method, df in fitting_results.groupby(\"method\"):\n",
    "    medians = df.groupby([\"mic\"]).offset.median()\n",
    "    [plt.axhline(m, color=palette[i], ls=ls[method]) for i, m in enumerate(medians)]\n",
    "    plt.plot([], [], color=\"black\", ls=ls[method], label=method)\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=[1, 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# old stuff"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from scipy.interpolate import UnivariateSpline, LSQUnivariateSpline\n",
    "from numpy.polynomial import Chebyshev, Legendre, Polynomial, Laguerre\n",
    "\n",
    "spline_k = 2\n",
    "spline_ext = 3\n",
    "\n",
    "for mic_idx in range(row.df_matrix.shape[0]):\n",
    "    df_norm, values = normalize_df_matrix(\n",
    "        df_matrix=row.df_matrix, freqs=row.df_freq, method=\"calibration-online\"\n",
    "    )\n",
    "\n",
    "    df_norm, df_freq, indices = prune_df_matrix(df_norm, row.df_freq)\n",
    "    values = values[:, indices]\n",
    "\n",
    "    xvalues = df_freq\n",
    "    yvalues = np.log10(values[mic_idx, :, 0])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(xvalues, yvalues, label=\"raw\", color=\"C0\", marker=\"*\")\n",
    "    for i, poly in enumerate([Legendre]):  \n",
    "        c = poly.fit(xvalues, yvalues, deg=10)\n",
    "        x, y = c.linspace()\n",
    "        plt.plot(x, y, label=poly.__name__, color=f\"C{i+1}\")\n",
    "\n",
    "    # spline = UnivariateSpline(xvalues, yvalues, k=2)\n",
    "    # plt.plot(xvalues, spline(xvalues), label='Spline', color='C5')\n",
    "\n",
    "    knots = np.linspace(min(df_freq), max(df_freq), 7)[1:-1]\n",
    "    spline = LSQUnivariateSpline(xvalues, yvalues, t=knots, k=spline_k, ext=spline_ext)\n",
    "    plt.plot(xvalues, spline(xvalues), label=\"LSQSpline\", color=f\"C{i+2}\", marker=\"o\")\n",
    "    [plt.axvline(k, color=f\"C{i+2}\") for k in knots]\n",
    "    plt.legend()\n",
    "    plt.title(f\"mic{mic_idx}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def spline_interpolation(xvalues, df_matrix):\n",
    "    \"\"\" Generate spline interpolation for all distances.\n",
    "    \n",
    "    :return calib_values: mics x freqs x distances, interpolated spline curve\n",
    "    \"\"\"\n",
    "    knots = np.linspace(min(df_freq), max(df_freq), 6)[1:-1]\n",
    "    calib_values = np.empty_like(df_matrix)\n",
    "    for i, dist in enumerate(row.df_dist):\n",
    "        for m in range(df_matrix.shape[0]):\n",
    "\n",
    "            slice_f = np.log10(df_matrix[m, :, i])\n",
    "            mask = ~np.isnan(slice_f)\n",
    "\n",
    "            spline = LSQUnivariateSpline(\n",
    "                xvalues[mask], slice_f[mask], t=knots, k=spline_k, ext=spline_ext\n",
    "            )\n",
    "            calib_values[m, :, i] = 10 ** spline(xvalues)\n",
    "    return calib_values\n",
    "\n",
    "\n",
    "df_matrix, df_freq, __ = prune_df_matrix(row.df_matrix, row.df_freq)\n",
    "calib_values = spline_interpolation(df_freq, df_matrix)\n",
    "\n",
    "fig, axs = plt.subplots(1, calib_values.shape[0], squeeze=False, sharey=True)\n",
    "fig.set_size_inches(10, 5)\n",
    "cmap = plt.get_cmap(\"inferno\")\n",
    "for m in range(calib_values.shape[0]):\n",
    "    for i, dist in enumerate(row.df_dist):\n",
    "        axs[0, m].semilogy(\n",
    "            df_freq, calib_values[m, :, i], color=cmap(i / len(row.df_dist))\n",
    "        )\n",
    "    axs[0, m].semilogy(\n",
    "        df_freq, calib_values[m, :, 0], color=cmap(0), label=f\"{row.df_dist[0]}cm\"\n",
    "    )\n",
    "    axs[0, m].semilogy(\n",
    "        df_freq,\n",
    "        calib_values[m, :, i],\n",
    "        color=cmap(i / len(row.df_dist)),\n",
    "        label=f\"{row.df_dist[-1]}cm\",\n",
    "    )\n",
    "    axs[0, m].set_title(f\"mic{m}\")\n",
    "    axs[0, m].legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282.883px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
