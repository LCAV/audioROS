{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "\n",
    "import IPython\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"figure.max_open_warning\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wall_analysis import parse_calibration_experiments\n",
    "\n",
    "fname = 'results/calibration.pkl'\n",
    "\n",
    "try:\n",
    "    df_total = pd.read_pickle(fname)\n",
    "    print('read', fname)\n",
    "except:\n",
    "    print('could not read', fname)\n",
    "    df_total = parse_calibration_experiments()\n",
    "    pd.to_pickle(df_total, fname)\n",
    "    print('saved as', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate psd for sweep without snr selection\n",
    "from wall_analysis import filter_by_dicts, extract_linear_psd\n",
    "\n",
    "dict_chosen = [{\n",
    "    'snr': 0,\n",
    "    'motors': 0,\n",
    "    'source': 'sweep',\n",
    "}]\n",
    "\n",
    "# found visually from spectrogram: \n",
    "sweep_lines = dict(\n",
    "    slope=4000/280,\n",
    "    offset=400,\n",
    "    delta=20,\n",
    ")\n",
    "\n",
    "df_chosen = filter_by_dicts(df_total, dict_chosen)\n",
    "for j, row in df_chosen.iterrows():\n",
    "    spec = np.sum(np.abs(row.signals_f), axis=1) # sum over all mics\n",
    "\n",
    "    fig, axs  = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(10, 5)\n",
    "    fig.suptitle(f'experiment \"{row.appendix}\"')\n",
    "    axs[0].pcolorfast(range(spec.shape[0]), row.frequencies, np.log10(spec.T))\n",
    "    psd = extract_linear_psd(row.signals_f, row.frequencies, ax=axs[0], **sweep_lines)\n",
    "\n",
    "    for i in range(psd.shape[0]):\n",
    "        axs[1].semilogy(row.frequencies, psd[i], label=f'mic{i}')\n",
    "    plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_psd_dict(signals_f, frequencies_matrix, min_t=0, max_t=None, n_freq=1, ax=None):\n",
    "    \"\"\"\n",
    "    Extract a hash table from the signals and frequencies information, one for \n",
    "    each microphone.\n",
    "    \n",
    "    structure of output: \n",
    "    \n",
    "    mic0: {\n",
    "        f0: [val0, val1],\n",
    "        f1: [val0, val1, val2], \n",
    "        f2: [...]\n",
    "    }\n",
    "    mic1: ...\n",
    "    \"\"\"\n",
    "    n_mics = signals_f.shape[1]\n",
    "    all_frequencies = np.unique(frequencies_matrix.flatten())\n",
    "\n",
    "    psd_dict = [{f:[] for f in all_frequencies} for i in range(n_mics)]\n",
    "\n",
    "    if max_t is None:\n",
    "        max_t = frequencies_matrix.shape[0]\n",
    "        \n",
    "    if ax is not None:\n",
    "        ax.plot(frequencies_matrix[:, 0])\n",
    "        ax.axvline(min_t, color='k')\n",
    "        ax.axvline(max_t, color='k')\n",
    "\n",
    "    for i_t in range(min_t, max_t): # n_times x n_freqs \n",
    "        # save strongest n_freq frequencies\n",
    "        fs = frequencies_matrix[i_t, :n_freq]\n",
    "        for i_mic in range(n_mics):\n",
    "            for f_idx, f in enumerate(fs):\n",
    "                psd_dict[i_mic][f].append(np.abs(signals_f[i_t, i_mic, f_idx]))\n",
    "    return psd_dict\n",
    "                \n",
    "def extract_psd(psd_dict_list, verbose=False):\n",
    "    \"\"\"\n",
    "    Combine hash tables in given list into one big hashtable, and compute the \n",
    "    median and std. \n",
    "    \n",
    "    \"\"\"\n",
    "    # extract all the different frequencies from psd_dict_list.\n",
    "    n_mics = len(psd_dict_list[0])\n",
    "    frequencies = set().union(*(psd_dict[i].keys() for psd_dict in psd_dict_list for i in range(n_mics)))\n",
    "    frequencies = np.sort(list(frequencies))\n",
    "    \n",
    "    psd = np.zeros((n_mics, len(frequencies)))\n",
    "    psd_std = np.zeros((n_mics, len(frequencies)))\n",
    "    for i_mic in range(n_mics):\n",
    "        for j, f in enumerate(frequencies):\n",
    "            \n",
    "            # combine all values at this f and mic\n",
    "            vals = []\n",
    "            for psd_dict in psd_dict_list:\n",
    "                if f in psd_dict[i_mic].keys():\n",
    "                    vals += psd_dict[i_mic][f]\n",
    "                    \n",
    "            if verbose:\n",
    "                print(f'for frequency {f}, mic{i_mic}, found {vals}')\n",
    "            if len(vals):\n",
    "                psd[i_mic, j] = np.median(vals) \n",
    "                psd_std[i_mic, j] = np.std(vals) \n",
    "                \n",
    "    # remove the frequencies for which we have no data\n",
    "    mask = np.any(psd > 0, axis=0)\n",
    "    return psd[:, mask], frequencies[mask], psd_std[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_dict1 = [{0: [], 100:[1, 2, 3], 200:[0, 4, 5]}, {100:[0, 1], 200:[1, 2]}]\n",
    "psd_dict2 = [{100:[1, 2, 5], 250:[1, 4, 5]}, {100:[0, 1], 250:[3, 4]}]\n",
    "psd_dict_list = [psd_dict1, psd_dict2]\n",
    "psd, frequencies, psd_std = extract_psd(psd_dict_list)\n",
    "print(psd.shape)\n",
    "print(psd, frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculate psd for sweep without snr selection\n",
    "from wall_analysis import filter_by_dicts\n",
    "\n",
    "dict_chosen = [{\n",
    "    'snr': 1,\n",
    "    'motors': 0,\n",
    "}]\n",
    "\n",
    "#from crazyflie_description_py.parameters import N_BUFFER, FS\n",
    "#all_frequencies = list(np.round(np.fft.rfftfreq(N_BUFFER, 1/FS)))\n",
    "#print(all_frequencies)\n",
    "\n",
    "kwargs = {\n",
    "    'sweep': {\n",
    "        'min_t': 105,\n",
    "        'max_t': 320\n",
    "    },\n",
    "    'sweep_buzzer': {\n",
    "        'min_t': 430,\n",
    "        'max_t': 1230\n",
    "    }\n",
    "}\n",
    "\n",
    "# need this to assign list to this columns\n",
    "df_total = df_total.assign(psd_dict=None)\n",
    "\n",
    "df_chosen = filter_by_dicts(df_total, dict_chosen)\n",
    "for source, df in df_chosen.groupby('source'):\n",
    "    fig, ax  = plt.subplots()\n",
    "    fig.set_size_inches(5, 5)\n",
    "    ax.grid(which='both')\n",
    "    for j, row in df.iterrows():\n",
    "        psd_dict = extract_psd_dict(row.signals_f, row.frequencies_matrix, ax=ax, **kwargs[source])\n",
    "        df_total.loc[j, 'psd_dict'] = psd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_harmonics = {\n",
    "    'sweep': {\n",
    "        'min_t': 40,\n",
    "        'max_t': 95 \n",
    "    },\n",
    "    'sweep_buzzer': {\n",
    "        'min_t': 40,\n",
    "        'max_t': 420 \n",
    "    }\n",
    "}\n",
    "\n",
    "# need this to assign list to this columns\n",
    "df_total = df_total.assign(psd_dict_harmonics=None)\n",
    "df_chosen = filter_by_dicts(df_total, dict_chosen)\n",
    "for source, df in df_chosen.groupby('source'):\n",
    "    fig, ax  = plt.subplots()\n",
    "    fig.set_size_inches(5, 5)\n",
    "    ax.grid(which='both')\n",
    "    for j, row in df.iterrows():\n",
    "        psd_dict_harmonics = extract_psd_dict(row.signals_f, row.frequencies_matrix, ax=ax, **kwargs_harmonics[source])\n",
    "        df_total.loc[j, 'psd_dict_harmonics'] = psd_dict_harmonics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mic_idx = 0\n",
    "\n",
    "df_chosen = filter_by_dicts(df_total, dict_chosen)\n",
    "for source, df in df_chosen.groupby('source'):\n",
    "    fig, axs = plt.subplots(len(df), sharey=True, sharex=True)\n",
    "    fig.set_size_inches(10, 10)\n",
    "    fig.suptitle(f'{source}')\n",
    "    \n",
    "    for j_idx, (j, row) in enumerate(df.iterrows()):\n",
    "        axs[j_idx].set_title(f'experiment \"{row.appendix}\"')\n",
    "        \n",
    "        for key, vals in row.psd_dict[mic_idx].items():\n",
    "            axs[j_idx].scatter([key]*len(vals), vals, c=range(len(vals)), cmap='inferno')\n",
    "        for key, vals in row.psd_dict_harmonics[mic_idx].items():\n",
    "            axs[j_idx].scatter([key]*len(vals), vals, c=range(len(vals)), cmap='cool')\n",
    "        \n",
    "        axs[j_idx].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for source, df in df_chosen.groupby('source'):\n",
    "    for j, row in df.iterrows():\n",
    "        n_mics = row.signals_f.shape[1]\n",
    "        \n",
    "        psd, frequencies, psd_std = extract_psd([row.psd_dict], verbose=False) \n",
    "        \n",
    "        fig, ax  = plt.subplots()\n",
    "        fig.set_size_inches(10, 5)\n",
    "        fig.suptitle(f'{source}: experiment \"{row.appendix}\"')\n",
    "        for i in range(n_mics):\n",
    "            mask = psd[i, :] > 0\n",
    "            ax.plot(frequencies[mask], psd[i, mask], color=f'C{i}', label=f'mic{i}', marker='o')\n",
    "        ax.set_yscale('log')\n",
    "        ax.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chosen experiments for calibration, based on variance above.  \n",
    "#chosen_experiments = ['_HALL', '_HALL2', '_HALL3']\n",
    "chosen_experiments = ['_HALL', '_HALL2']\n",
    "\n",
    "df_calib = pd.DataFrame(index=[], columns=['frequencies', 'psd', 'psd_std', 'type', 'source'])\n",
    "\n",
    "for source, df in df_chosen.groupby('source'):\n",
    "    for type_ in ['psd_dict', 'psd_dict_harmonics']:\n",
    "        \n",
    "        psd_dict_list = []\n",
    "        for appendix in chosen_experiments:\n",
    "            psd_dict = list(df.loc[df.appendix==appendix, type_].values)\n",
    "            psd_dict_list += psd_dict\n",
    "    \n",
    "        psd, frequencies, psd_std = extract_psd(psd_dict_list, verbose=False) \n",
    "        df_calib.loc[len(df_calib), :] = {\n",
    "            'frequencies': frequencies,\n",
    "            'psd': psd, \n",
    "            'psd_std': psd_std, \n",
    "            'type': type_, \n",
    "            'source': source\n",
    "        }\n",
    "    \n",
    "fname = f'results/calibration_results.pkl'\n",
    "pd.to_pickle(df_calib, fname)\n",
    "print(f'saved as {fname}')\n",
    "#df_chosen = df_total.loc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_calib.psd.values.shape)\n",
    "psd_all = np.concatenate(df_calib.psd.values, axis=1)\n",
    "freqs_all = np.concatenate(df_calib.frequencies.values)\n",
    "y_min = np.min(psd_all)\n",
    "y_max = np.max(psd_all)\n",
    "x_min = np.min(freqs_all) \n",
    "x_max = np.max(freqs_all) \n",
    "\n",
    "for i, row in df_calib.iterrows():\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(7, 5)\n",
    "    ax.set_title(f'{row.source}{row.type.replace(\"psd_dict\", \"\")}')\n",
    "    for i in range(row.psd.shape[0]):\n",
    "        ax.errorbar(x=row.frequencies, y=row.psd[i, :], yerr=row.psd_std[i, :])\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xlim(x_min, x_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes for next steps\n",
    "\n",
    "- potentially discard the first and last measurements (check final result with and without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
